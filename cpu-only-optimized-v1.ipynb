{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-08-02T05:21:01.884035Z","iopub.status.busy":"2025-08-02T05:21:01.883648Z","iopub.status.idle":"2025-08-02T05:21:02.235031Z","shell.execute_reply":"2025-08-02T05:21:02.234028Z","shell.execute_reply.started":"2025-08-02T05:21:01.884007Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"execution_failed":"2025-08-02T06:25:20.851Z","iopub.execute_input":"2025-08-02T06:25:13.974618Z","iopub.status.busy":"2025-08-02T06:25:13.974121Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","import subprocess\n","\n","# Define required packages\n","REQUIRED_PACKAGES = [\n","    \"torch\",\n","    \"torch-geometric\",\n","    \"rdkit-pypi\",\n","    \"pandas\",\n","    \"numpy\",\n","    \"scikit-learn\",\n","    \"tqdm\",\n","    \"matplotlib\",\n","    \"seaborn\"\n","]\n","\n","# Function to check and install missing packages\n","def install_and_restart_if_needed(packages):\n","    import pkg_resources\n","    missing_packages = []\n","    for package in packages:\n","        try:\n","            # Special handling for package name differences (like rdkit)\n","            pkg_resources.get_distribution(package if package != \"rdkit-pypi\" else \"rdkit\")\n","        except pkg_resources.DistributionNotFound:\n","            missing_packages.append(package)\n","    if missing_packages:\n","        print(f\"Installing missing packages: {missing_packages}\")\n","        # Install with --quiet for a cleaner output, you can drop --quiet if you want detailed logs\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\"] + missing_packages)\n","        # After installing, force a kernel restart\n","        os._exit(0)\n","\n","# Run the installer/restarting code\n","install_and_restart_if_needed(REQUIRED_PACKAGES)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-02T06:25:36.704109Z","iopub.status.busy":"2025-08-02T06:25:36.703462Z","iopub.status.idle":"2025-08-02T06:25:36.745080Z","shell.execute_reply":"2025-08-02T06:25:36.744086Z","shell.execute_reply.started":"2025-08-02T06:25:36.704081Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","import random\n","import warnings\n","from datetime import datetime\n","from typing import List, Dict, Tuple, Optional\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import random_split\n","from torch_geometric.data import Data, Dataset, DataLoader\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","from rdkit import Chem\n","from rdkit.Chem import rdchem\n","from rdkit import RDLogger\n","\n","# Suppress warnings\n","RDLogger.DisableLog('rdApp.*')\n","warnings.filterwarnings('ignore')\n","\n","# Set CPU threads for optimization\n","torch.set_num_threads(8)  # Adjust based on your CPU cores\n","\n","# Check PyTorch\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(\"Device: CPU\")\n","\n","# Set seed\n","def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","\n","set_seed(42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-02T06:25:36.758772Z","iopub.status.busy":"2025-08-02T06:25:36.756475Z","iopub.status.idle":"2025-08-02T06:25:38.812327Z","shell.execute_reply":"2025-08-02T06:25:38.811344Z","shell.execute_reply.started":"2025-08-02T06:25:36.758731Z"},"trusted":true},"outputs":[],"source":["class Config:\n","    DEVICE = torch.device(\"cpu\")\n","    BATCH_SIZE = 64\n","    LEARNING_RATE = 2e-3\n","    WEIGHT_DECAY = 1e-5\n","    HIDDEN_CHANNELS = 128\n","    NUM_GCN_LAYERS = 3\n","    NUM_EPOCHS = 100\n","    VAL_SPLIT_FRACTION = 0.2\n","    SEED = 42\n","    TARGET_PROPERTIES = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n","    GRAD_ACCUM_STEPS = 2\n","    EARLY_STOP_PATIENCE = 15\n","\n","CONFIG = Config()\n","\n","def load_data():\n","    # Assuming data paths; adjust as needed\n","    train_df = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\n","    test_df = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')\n","    print(f\"Loaded training data: {len(train_df)} samples\")\n","    print(f\"Loaded test data: {len(test_df)} samples\")\n","    return train_df, test_df\n","\n","train_df, test_df = load_data()\n","\n","# EDA: Missing values heatmap\n","plt.figure(figsize=(10, 6))\n","sns.heatmap(train_df[CONFIG.TARGET_PROPERTIES].isnull(), cbar=False, cmap='viridis')\n","plt.title('Missing Values Heatmap')\n","plt.show()\n","\n","# Histograms for each target\n","for prop in CONFIG.TARGET_PROPERTIES:\n","    plt.figure(figsize=(8, 4))\n","    sns.histplot(train_df[prop].dropna(), kde=True)\n","    plt.title(f'Distribution of {prop}')\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-02T06:26:25.177904Z","iopub.status.busy":"2025-08-02T06:26:25.177529Z","iopub.status.idle":"2025-08-02T06:26:25.193985Z","shell.execute_reply":"2025-08-02T06:26:25.192939Z","shell.execute_reply.started":"2025-08-02T06:26:25.177871Z"},"trusted":true},"outputs":[],"source":["ATOM_TYPES = ['C', 'O', 'N', 'F', 'S', 'Cl', 'Br', 'I', 'P', 'B', 'Si']  # 11 common atoms\n","HYBRID_TYPES = [rdchem.HybridizationType.SP, rdchem.HybridizationType.SP2, rdchem.HybridizationType.SP3]  # 3 types\n","\n","def get_atom_features(atom):\n","    return [\n","        atom.GetAtomicNum(),\n","        atom.GetTotalNumHs(),\n","        atom.GetDegree(),\n","        atom.GetFormalCharge(),\n","        atom.GetHybridization(),\n","        atom.GetTotalValence(),\n","        atom.GetImplicitValence(),\n","        int(atom.GetChiralTag() != rdchem.ChiralType.CHI_UNSPECIFIED),\n","        # FIXED: Use GetOwningMol() instead of HasOwningMol()\n","        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 3)),\n","        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 4)),\n","        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 5)),\n","        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 6)),\n","        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 7)),\n","        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 8)),\n","        int(atom.GetIsAromatic()),\n","    ]\n","\n","def get_bond_features(bond):\n","    # 4 types + ring + conjugation = 7 dims\n","    bond_type = bond.GetBondTypeAsDouble()\n","    onehot_type = [int(bond_type == x) for x in [1.0, 1.5, 2.0, 3.0]]\n","    in_ring = int(bond.IsInRing())\n","    conjugated = int(bond.GetIsConjugated())\n","    stereo = int(bond.GetStereo() > 0)\n","    return np.array(onehot_type + [in_ring, conjugated, stereo], dtype=np.float32)\n","\n","graph_cache = {}\n","\n","def smiles_to_graph(smiles, y=None, mask=None, idx=None):\n","    if idx in graph_cache:\n","        return graph_cache[idx]\n","    \n","    mol = Chem.MolFromSmiles(smiles)\n","    if mol is None:\n","        return None\n","    \n","    num_atoms = mol.GetNumAtoms()\n","    x = np.zeros((num_atoms, 15))  # 15 dims (hotfix)\n","    edge_index = []\n","    edge_attr = []\n","    \n","    for atom in mol.GetAtoms():\n","        x[atom.GetIdx()] = get_atom_features(atom)\n","    \n","    for bond in mol.GetBonds():\n","        i = bond.GetBeginAtomIdx()\n","        j = bond.GetEndAtomIdx()\n","        edge_index.extend([[i, j], [j, i]])\n","        e_feat = get_bond_features(bond)\n","        edge_attr.extend([e_feat, e_feat])\n","    \n","    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n","    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n","    x = torch.tensor(x, dtype=torch.float)\n","    \n","    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n","    if y is not None:\n","        data.y = torch.tensor(y, dtype=torch.float)\n","    if mask is not None:\n","        data.mask = torch.tensor(mask, dtype=torch.float)\n","    if idx is not None:\n","        graph_cache[idx] = data\n","    \n","    return data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-02T06:26:35.386759Z","iopub.status.busy":"2025-08-02T06:26:35.386414Z","iopub.status.idle":"2025-08-02T06:26:35.395211Z","shell.execute_reply":"2025-08-02T06:26:35.393917Z","shell.execute_reply.started":"2025-08-02T06:26:35.386735Z"},"trusted":true},"outputs":[],"source":["\n","class PolymerDataset(Dataset):\n","    \"\"\"\n","    Custom PyTorch Dataset for polymer graph data.\n","    \n","    Processes a DataFrame containing SMILES strings and target properties,\n","    converting each row into a graph data object for use in a GNN.\n","    \"\"\"\n","    def __init__(self, df: pd.DataFrame, is_test: bool = False):\n","        self.df = df\n","        self.is_test = is_test\n","        self.graphs = []\n","\n","        # Use tqdm for a progress bar during data processing\n","        for i, row in tqdm(self.df.iterrows(), total=len(df), desc=\"Processing data\"):\n","            y = None\n","            mask = None\n","            \n","            # Only process targets and masks if it's not a test set\n","            if not self.is_test:\n","                # 1. Select the target columns as a pandas Series\n","                targets_series = row[CONFIG.TARGET_PROPERTIES]\n","                \n","                # 2. Create the mask from the Series *before* filling NaNs\n","                # This correctly identifies original missing values\n","                mask = (~pd.isnull(targets_series)).astype('float32').values\n","\n","                # 3. Fill NaNs with 0 and convert to a numeric numpy array.\n","                # This is a robust way to prevent the `dtype=object` error.\n","                y = targets_series.fillna(0).astype('float32').values\n","\n","            # Convert the SMILES string and its associated data into a graph\n","            graph = smiles_to_graph(row['SMILES'], y=y, mask=mask, idx=i)\n","            \n","            # Some SMILES might be invalid, so we only append if a graph is successfully created\n","            if graph:\n","                self.graphs.append(graph)\n","\n","    def __len__(self) -> int:\n","        \"\"\"Returns the total number of graphs in the dataset.\"\"\"\n","        return len(self.graphs)\n","\n","    def __getitem__(self, idx: int):\n","        \"\"\"Fetches the graph at the specified index.\"\"\"\n","        return self.graphs[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-02T06:26:39.255122Z","iopub.status.busy":"2025-08-02T06:26:39.253629Z","iopub.status.idle":"2025-08-02T06:26:39.263771Z","shell.execute_reply":"2025-08-02T06:26:39.262539Z","shell.execute_reply.started":"2025-08-02T06:26:39.255079Z"},"trusted":true},"outputs":[],"source":["class PolymerGCN(nn.Module):\n","    def __init__(self, input_dim=26, hidden_channels=CONFIG.HIDDEN_CHANNELS, num_layers=CONFIG.NUM_GCN_LAYERS, output_dim=5):\n","        super().__init__()\n","        self.convs = nn.ModuleList()\n","        self.convs.append(GCNConv(input_dim, hidden_channels))\n","        for _ in range(1, num_layers):\n","            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n","        self.lin1 = nn.Linear(hidden_channels, hidden_channels)\n","        self.lin2 = nn.Linear(hidden_channels, output_dim)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        for conv in self.convs:\n","            x = F.relu(conv(x, edge_index))\n","        x = global_mean_pool(x, batch)\n","        x = F.relu(self.lin1(x))\n","        x = self.lin2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-02T06:26:42.141522Z","iopub.status.busy":"2025-08-02T06:26:42.141148Z","iopub.status.idle":"2025-08-02T06:26:42.147831Z","shell.execute_reply":"2025-08-02T06:26:42.146586Z","shell.execute_reply.started":"2025-08-02T06:26:42.141502Z"},"trusted":true},"outputs":[],"source":["def wmae_loss(pred, target, mask, weights=[0.2, 0.2, 0.2, 0.2, 0.2]):\n","    weights = torch.tensor(weights, device=CONFIG.DEVICE)\n","    diff = torch.abs(pred - target) * mask\n","    weighted_diff = diff * weights\n","    return torch.sum(weighted_diff) / torch.sum(mask)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-02T06:26:44.705695Z","iopub.status.busy":"2025-08-02T06:26:44.705273Z","iopub.status.idle":"2025-08-02T06:26:44.715906Z","shell.execute_reply":"2025-08-02T06:26:44.714931Z","shell.execute_reply.started":"2025-08-02T06:26:44.705562Z"},"trusted":true},"outputs":[],"source":["def train_model(train_loader, val_loader):\n","    model = PolymerGCN().to(CONFIG.DEVICE)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG.LEARNING_RATE, weight_decay=CONFIG.WEIGHT_DECAY)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=CONFIG.NUM_EPOCHS)\n","    best_val_loss = float('inf')\n","    patience_counter = 0\n","\n","    for epoch in range(CONFIG.NUM_EPOCHS):\n","        model.train()\n","        train_loss = 0\n","        optimizer.zero_grad()\n","        for i, data in enumerate(train_loader):\n","            data = data.to(CONFIG.DEVICE)\n","            out = model(data)\n","            loss = wmae_loss(out, data.y, data.mask) / CONFIG.GRAD_ACCUM_STEPS\n","            loss.backward()\n","            if (i + 1) % CONFIG.GRAD_ACCUM_STEPS == 0:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","            train_loss += loss.item() * CONFIG.GRAD_ACCUM_STEPS\n","\n","        val_loss = evaluate(model, val_loader)\n","        scheduler.step()\n","\n","        print(f'Epoch {epoch+1}: Train Loss {train_loss/len(train_loader):.4f}, Val Loss {val_loss:.4f}')\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), 'best_model.pth')\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= CONFIG.EARLY_STOP_PATIENCE:\n","                print(\"Early stopping\")\n","                break\n","\n","    return model\n","\n","def evaluate(model, loader):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","        for data in loader:\n","            data = data.to(CONFIG.DEVICE)\n","            out = model(data)\n","            loss = wmae_loss(out, data.y, data.mask)\n","            total_loss += loss.item()\n","    return total_loss / len(loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Prepare datasets\n","full_dataset = PolymerDataset(train_df)\n","train_size = int((1 - CONFIG.VAL_SPLIT_FRACTION) * len(full_dataset))\n","train_dataset, val_dataset = random_split(full_dataset, [train_size, len(full_dataset) - train_size])\n","train_loader = DataLoader(train_dataset, batch_size=CONFIG.BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=CONFIG.BATCH_SIZE)\n","\n","# Train\n","model = train_model(train_loader, val_loader)\n","\n","# Inference on test\n","test_dataset = PolymerDataset(test_df, is_test=True)\n","test_loader = DataLoader(test_dataset, batch_size=CONFIG.BATCH_SIZE)\n","model.load_state_dict(torch.load('best_model.pth'))\n","model.eval()\n","\n","predictions = []\n","with torch.no_grad():\n","    for data in test_loader:\n","        data = data.to(CONFIG.DEVICE)\n","        out = model(data)\n","        predictions.extend(out.cpu().numpy())\n","\n","submission = pd.DataFrame(predictions, columns=CONFIG.TARGET_PROPERTIES)\n","submission['id'] = test_df['id']\n","submission.to_csv('submission.csv', index=False)\n","print(\"Submission file created: submission.csv\")\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":12966160,"sourceId":74608,"sourceType":"competition"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
