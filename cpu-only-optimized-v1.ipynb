{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":74608,"databundleVersionId":12966160,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-02T05:21:01.883648Z","iopub.execute_input":"2025-08-02T05:21:01.884035Z","iopub.status.idle":"2025-08-02T05:21:02.235031Z","shell.execute_reply.started":"2025-08-02T05:21:01.884007Z","shell.execute_reply":"2025-08-02T05:21:02.234028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport sys\nimport subprocess\n\n# Define required packages\nREQUIRED_PACKAGES = [\n    \"torch\",\n    \"torch-geometric\",\n    \"rdkit-pypi\",\n    \"pandas\",\n    \"numpy\",\n    \"scikit-learn\",\n    \"tqdm\",\n    \"matplotlib\",\n    \"seaborn\"\n]\n\n# Function to check and install missing packages\ndef install_and_restart_if_needed(packages):\n    import pkg_resources\n    missing_packages = []\n    for package in packages:\n        try:\n            # Special handling for package name differences (like rdkit)\n            pkg_resources.get_distribution(package if package != \"rdkit-pypi\" else \"rdkit\")\n        except pkg_resources.DistributionNotFound:\n            missing_packages.append(package)\n    if missing_packages:\n        print(f\"Installing missing packages: {missing_packages}\")\n        # Install with --quiet for a cleaner output, you can drop --quiet if you want detailed logs\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\"] + missing_packages)\n        # After installing, force a kernel restart\n        os._exit(0)\n\n# Run the installer/restarting code\ninstall_and_restart_if_needed(REQUIRED_PACKAGES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T06:25:13.974121Z","iopub.execute_input":"2025-08-02T06:25:13.974618Z","execution_failed":"2025-08-02T06:25:20.851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport warnings\nfrom datetime import datetime\nfrom typing import List, Dict, Tuple, Optional\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import random_split\nfrom torch_geometric.data import Data, Dataset, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom rdkit import Chem\nfrom rdkit.Chem import rdchem\nfrom rdkit import RDLogger\n\n# Suppress warnings\nRDLogger.DisableLog('rdApp.*')\nwarnings.filterwarnings('ignore')\n\n# Set CPU threads for optimization\ntorch.set_num_threads(8)  # Adjust based on your CPU cores\n\n# Check PyTorch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(\"Device: CPU\")\n\n# Set seed\ndef set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n\nset_seed(42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T06:25:36.703462Z","iopub.execute_input":"2025-08-02T06:25:36.704109Z","iopub.status.idle":"2025-08-02T06:25:36.745080Z","shell.execute_reply.started":"2025-08-02T06:25:36.704081Z","shell.execute_reply":"2025-08-02T06:25:36.744086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Config:\n    DEVICE = torch.device(\"cpu\")\n    BATCH_SIZE = 64\n    LEARNING_RATE = 2e-3\n    WEIGHT_DECAY = 1e-5\n    HIDDEN_CHANNELS = 128\n    NUM_GCN_LAYERS = 3\n    NUM_EPOCHS = 100\n    VAL_SPLIT_FRACTION = 0.2\n    SEED = 42\n    TARGET_PROPERTIES = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n    GRAD_ACCUM_STEPS = 2\n    EARLY_STOP_PATIENCE = 15\n\nCONFIG = Config()\n\ndef load_data():\n    # Assuming data paths; adjust as needed\n    train_df = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\n    test_df = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')\n    print(f\"Loaded training data: {len(train_df)} samples\")\n    print(f\"Loaded test data: {len(test_df)} samples\")\n    return train_df, test_df\n\ntrain_df, test_df = load_data()\n\n# EDA: Missing values heatmap\nplt.figure(figsize=(10, 6))\nsns.heatmap(train_df[CONFIG.TARGET_PROPERTIES].isnull(), cbar=False, cmap='viridis')\nplt.title('Missing Values Heatmap')\nplt.show()\n\n# Histograms for each target\nfor prop in CONFIG.TARGET_PROPERTIES:\n    plt.figure(figsize=(8, 4))\n    sns.histplot(train_df[prop].dropna(), kde=True)\n    plt.title(f'Distribution of {prop}')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T06:25:36.756475Z","iopub.execute_input":"2025-08-02T06:25:36.758772Z","iopub.status.idle":"2025-08-02T06:25:38.812327Z","shell.execute_reply.started":"2025-08-02T06:25:36.758731Z","shell.execute_reply":"2025-08-02T06:25:38.811344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ATOM_TYPES = ['C', 'O', 'N', 'F', 'S', 'Cl', 'Br', 'I', 'P', 'B', 'Si']  # 11 common atoms\nHYBRID_TYPES = [rdchem.HybridizationType.SP, rdchem.HybridizationType.SP2, rdchem.HybridizationType.SP3]  # 3 types\n\ndef get_atom_features(atom):\n    return [\n        atom.GetAtomicNum(),\n        atom.GetTotalNumHs(),\n        atom.GetDegree(),\n        atom.GetFormalCharge(),\n        atom.GetHybridization(),\n        atom.GetTotalValence(),\n        atom.GetImplicitValence(),\n        int(atom.GetChiralTag() != rdchem.ChiralType.CHI_UNSPECIFIED),\n        # FIXED: Use GetOwningMol() instead of HasOwningMol()\n        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 3)),\n        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 4)),\n        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 5)),\n        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 6)),\n        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 7)),\n        int(atom.GetOwningMol().GetRingInfo().IsAtomInRingOfSize(atom.GetIdx(), 8)),\n        int(atom.GetIsAromatic()),\n    ]\n\ndef get_bond_features(bond):\n    # 4 types + ring + conjugation = 7 dims\n    bond_type = bond.GetBondTypeAsDouble()\n    onehot_type = [int(bond_type == x) for x in [1.0, 1.5, 2.0, 3.0]]\n    in_ring = int(bond.IsInRing())\n    conjugated = int(bond.GetIsConjugated())\n    stereo = int(bond.GetStereo() > 0)\n    return np.array(onehot_type + [in_ring, conjugated, stereo], dtype=np.float32)\n\ngraph_cache = {}\n\ndef smiles_to_graph(smiles, y=None, mask=None, idx=None):\n    if idx in graph_cache:\n        return graph_cache[idx]\n    \n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return None\n    \n    num_atoms = mol.GetNumAtoms()\n    x = np.zeros((num_atoms, 15))  # 15 dims (hotfix)\n    edge_index = []\n    edge_attr = []\n    \n    for atom in mol.GetAtoms():\n        x[atom.GetIdx()] = get_atom_features(atom)\n    \n    for bond in mol.GetBonds():\n        i = bond.GetBeginAtomIdx()\n        j = bond.GetEndAtomIdx()\n        edge_index.extend([[i, j], [j, i]])\n        e_feat = get_bond_features(bond)\n        edge_attr.extend([e_feat, e_feat])\n    \n    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n    x = torch.tensor(x, dtype=torch.float)\n    \n    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n    if y is not None:\n        data.y = torch.tensor(y, dtype=torch.float)\n    if mask is not None:\n        data.mask = torch.tensor(mask, dtype=torch.float)\n    if idx is not None:\n        graph_cache[idx] = data\n    \n    return data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T06:26:25.177529Z","iopub.execute_input":"2025-08-02T06:26:25.177904Z","iopub.status.idle":"2025-08-02T06:26:25.193985Z","shell.execute_reply.started":"2025-08-02T06:26:25.177871Z","shell.execute_reply":"2025-08-02T06:26:25.192939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass PolymerDataset(Dataset):\n    \"\"\"\n    Custom PyTorch Dataset for polymer graph data.\n    \n    Processes a DataFrame containing SMILES strings and target properties,\n    converting each row into a graph data object for use in a GNN.\n    \"\"\"\n    def __init__(self, df: pd.DataFrame, is_test: bool = False):\n        self.df = df\n        self.is_test = is_test\n        self.graphs = []\n\n        # Use tqdm for a progress bar during data processing\n        for i, row in tqdm(self.df.iterrows(), total=len(df), desc=\"Processing data\"):\n            y = None\n            mask = None\n            \n            # Only process targets and masks if it's not a test set\n            if not self.is_test:\n                # 1. Select the target columns as a pandas Series\n                targets_series = row[CONFIG.TARGET_PROPERTIES]\n                \n                # 2. Create the mask from the Series *before* filling NaNs\n                # This correctly identifies original missing values\n                mask = (~pd.isnull(targets_series)).astype('float32').values\n\n                # 3. Fill NaNs with 0 and convert to a numeric numpy array.\n                # This is a robust way to prevent the `dtype=object` error.\n                y = targets_series.fillna(0).astype('float32').values\n\n            # Convert the SMILES string and its associated data into a graph\n            graph = smiles_to_graph(row['SMILES'], y=y, mask=mask, idx=i)\n            \n            # Some SMILES might be invalid, so we only append if a graph is successfully created\n            if graph:\n                self.graphs.append(graph)\n\n    def __len__(self) -> int:\n        \"\"\"Returns the total number of graphs in the dataset.\"\"\"\n        return len(self.graphs)\n\n    def __getitem__(self, idx: int):\n        \"\"\"Fetches the graph at the specified index.\"\"\"\n        return self.graphs[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T06:26:35.386414Z","iopub.execute_input":"2025-08-02T06:26:35.386759Z","iopub.status.idle":"2025-08-02T06:26:35.395211Z","shell.execute_reply.started":"2025-08-02T06:26:35.386735Z","shell.execute_reply":"2025-08-02T06:26:35.393917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PolymerGCN(nn.Module):\n    def __init__(self, input_dim=26, hidden_channels=CONFIG.HIDDEN_CHANNELS, num_layers=CONFIG.NUM_GCN_LAYERS, output_dim=5):\n        super().__init__()\n        self.convs = nn.ModuleList()\n        self.convs.append(GCNConv(input_dim, hidden_channels))\n        for _ in range(1, num_layers):\n            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n        self.lin1 = nn.Linear(hidden_channels, hidden_channels)\n        self.lin2 = nn.Linear(hidden_channels, output_dim)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        for conv in self.convs:\n            x = F.relu(conv(x, edge_index))\n        x = global_mean_pool(x, batch)\n        x = F.relu(self.lin1(x))\n        x = self.lin2(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T06:26:39.253629Z","iopub.execute_input":"2025-08-02T06:26:39.255122Z","iopub.status.idle":"2025-08-02T06:26:39.263771Z","shell.execute_reply.started":"2025-08-02T06:26:39.255079Z","shell.execute_reply":"2025-08-02T06:26:39.262539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def wmae_loss(pred, target, mask, weights=[0.2, 0.2, 0.2, 0.2, 0.2]):\n    weights = torch.tensor(weights, device=CONFIG.DEVICE)\n    diff = torch.abs(pred - target) * mask\n    weighted_diff = diff * weights\n    return torch.sum(weighted_diff) / torch.sum(mask)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T06:26:42.141148Z","iopub.execute_input":"2025-08-02T06:26:42.141522Z","iopub.status.idle":"2025-08-02T06:26:42.147831Z","shell.execute_reply.started":"2025-08-02T06:26:42.141502Z","shell.execute_reply":"2025-08-02T06:26:42.146586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(train_loader, val_loader):\n    model = PolymerGCN().to(CONFIG.DEVICE)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG.LEARNING_RATE, weight_decay=CONFIG.WEIGHT_DECAY)\n    scheduler = CosineAnnealingLR(optimizer, T_max=CONFIG.NUM_EPOCHS)\n    best_val_loss = float('inf')\n    patience_counter = 0\n\n    for epoch in range(CONFIG.NUM_EPOCHS):\n        model.train()\n        train_loss = 0\n        optimizer.zero_grad()\n        for i, data in enumerate(train_loader):\n            data = data.to(CONFIG.DEVICE)\n            out = model(data)\n            loss = wmae_loss(out, data.y, data.mask) / CONFIG.GRAD_ACCUM_STEPS\n            loss.backward()\n            if (i + 1) % CONFIG.GRAD_ACCUM_STEPS == 0:\n                optimizer.step()\n                optimizer.zero_grad()\n            train_loss += loss.item() * CONFIG.GRAD_ACCUM_STEPS\n\n        val_loss = evaluate(model, val_loader)\n        scheduler.step()\n\n        print(f'Epoch {epoch+1}: Train Loss {train_loss/len(train_loader):.4f}, Val Loss {val_loss:.4f}')\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), 'best_model.pth')\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= CONFIG.EARLY_STOP_PATIENCE:\n                print(\"Early stopping\")\n                break\n\n    return model\n\ndef evaluate(model, loader):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for data in loader:\n            data = data.to(CONFIG.DEVICE)\n            out = model(data)\n            loss = wmae_loss(out, data.y, data.mask)\n            total_loss += loss.item()\n    return total_loss / len(loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T06:26:44.705273Z","iopub.execute_input":"2025-08-02T06:26:44.705695Z","iopub.status.idle":"2025-08-02T06:26:44.715906Z","shell.execute_reply.started":"2025-08-02T06:26:44.705562Z","shell.execute_reply":"2025-08-02T06:26:44.714931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare datasets\nfull_dataset = PolymerDataset(train_df)\ntrain_size = int((1 - CONFIG.VAL_SPLIT_FRACTION) * len(full_dataset))\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, len(full_dataset) - train_size])\ntrain_loader = DataLoader(train_dataset, batch_size=CONFIG.BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=CONFIG.BATCH_SIZE)\n\n# Train\nmodel = train_model(train_loader, val_loader)\n\n# Inference on test\ntest_dataset = PolymerDataset(test_df, is_test=True)\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG.BATCH_SIZE)\nmodel.load_state_dict(torch.load('best_model.pth'))\nmodel.eval()\n\npredictions = []\nwith torch.no_grad():\n    for data in test_loader:\n        data = data.to(CONFIG.DEVICE)\n        out = model(data)\n        predictions.extend(out.cpu().numpy())\n\nsubmission = pd.DataFrame(predictions, columns=CONFIG.TARGET_PROPERTIES)\nsubmission['id'] = test_df['id']\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created: submission.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}