{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":74608,"databundleVersionId":12966160,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NeurIPS Open Polymer Prediction 2025 - CPU Optimized Solution with Optuna\n\n**Hardware**: CPU-only environment  \n**Expected Performance**: ~0.135-0.145 wMAE (optimized)  \n**Training Time**: ~60-90 minutes (including hyperparameter optimization)  \n**Key Features**: \n- Optuna hyperparameter optimization\n- CPU-optimized training parameters\n- Robust error handling\n- Automatic model selection\n\nThis notebook combines CPU-optimized training with Optuna hyperparameter optimization to achieve better performance through automated parameter tuning.","metadata":{}},{"cell_type":"code","source":"# NeurIPS Open Polymer Prediction 2025 - Fixed CPU-Bound Kaggle Solution\n# This single-cell code provides a working solution with proper error handling,\n# updated RDKit usage, and fixed model fitting issues.\n\n# Step 1: Install required packages (CPU-only)\nimport sys\nimport subprocess\n\ndef install_packages():\n    packages = [\n        'rdkit',\n        'xgboost',\n        'lightgbm',\n        'catboost',\n        'optuna',\n        'scikit-learn',\n        'pandas',\n        'numpy'\n    ]\n    for package in packages:\n        try:\n            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--quiet', package])\n        except Exception as e:\n            print(f\"Warning: Failed to install {package}: {e}\")\n\n# Uncomment if packages need to be installed\n# install_packages()\n\n# Step 2: Import libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.base import BaseEstimator, RegressorMixin\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\nimport optuna\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors, rdMolDescriptors\nfrom rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator  # Updated RDKit usage\nimport logging\nimport gc\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# Configuration\nclass Config:\n    DATA_PATH = '/kaggle/input/neurips-open-polymer-prediction-2025'  # Adjust if needed\n    TARGET_COLS = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n    N_FOLDS = 7\n    RANDOM_STATE = 42\n    MORGAN_BITS = 2048\n    N_TRIALS = 20  # Reduced for CPU efficiency\n    EARLY_STOPPING_ROUNDS = 30\n\nconfig = Config()\nnp.random.seed(config.RANDOM_STATE)\n\n# Step 3: Data Loading\ndef load_data():\n    try:\n        train_df = pd.read_csv(f'{config.DATA_PATH}/train.csv')\n        test_df = pd.read_csv(f'{config.DATA_PATH}/test.csv')\n        logger.info(f\"Data loaded: Train {train_df.shape}, Test {test_df.shape}\")\n        return train_df, test_df\n    except Exception as e:\n        logger.error(f\"Data loading failed: {e}\")\n        raise\n\n# Step 4: Feature Engineering (Fixed RDKit usage)\nclass FeatureExtractor:\n    def __init__(self):\n        # Initialize Morgan generator to avoid deprecation warning\n        self.morgan_gen = GetMorganGenerator(radius=2, fpSize=config.MORGAN_BITS)\n    \n    def extract(self, smiles_list, is_train=True):\n        features = []\n        successful_extractions = 0\n        \n        for i, smiles in enumerate(smiles_list):\n            try:\n                mol = Chem.MolFromSmiles(smiles)\n                if mol is None:\n                    features.append(np.zeros(50 + config.MORGAN_BITS))  # Reduced feature size\n                    continue\n                \n                # RDKit descriptors (key ones for efficiency)\n                desc = []\n                try:\n                    desc.extend([\n                Descriptors.MolWt(mol),\n                Descriptors.MolLogP(mol),\n                Descriptors.TPSA(mol),\n                Descriptors.NumRotatableBonds(mol),\n                Descriptors.NumHDonors(mol),\n                Descriptors.NumHAcceptors(mol),\n                Descriptors.NumAromaticRings(mol),\n                Descriptors.NumSaturatedRings(mol),\n                Descriptors.NumAliphaticRings(mol),\n                Descriptors.FractionCsp3(mol),\n                Descriptors.HeavyAtomCount(mol),\n                Descriptors.NumHeteroatoms(mol),\n                Descriptors.RingCount(mol),\n                Descriptors.BertzCT(mol),\n                Descriptors.BalabanJ(mol),\n                Descriptors.Chi0v(mol),\n                Descriptors.Chi1v(mol),\n                Descriptors.Chi2v(mol),\n                Descriptors.Chi3v(mol),\n                Descriptors.Chi4v(mol),\n                Descriptors.Kappa1(mol),\n                Descriptors.Kappa2(mol),\n                Descriptors.Kappa3(mol),\n                        # Add basic atom counts\n                        mol.GetNumAtoms(),\n                        mol.GetNumBonds(),\n                        # Add simple polymer-specific features\n                        mol.GetNumAtoms(),\n                        mol.GetNumBonds(),\n                        mol.GetNumConformers(),\n                        rdMolDescriptors.CalcNumRotatableBonds(mol),\n                        rdMolDescriptors.CalcNumHBD(mol),\n                        rdMolDescriptors.CalcNumHBA(mol),\n                        rdMolDescriptors.CalcNumRings(mol),\n                        rdMolDescriptors.CalcNumAromaticRings(mol),\n                        rdMolDescriptors.CalcNumSaturatedRings(mol),\n                        rdMolDescriptors.CalcNumAliphaticRings(mol),\n                        smiles.count('*'),  # Connection points\n                        len(smiles),        # SMILES length\n                        smiles.count('C'),  # Carbon count\n                        smiles.count('N'),  # Nitrogen count\n                        smiles.count('O'),  # Oxygen count\n                        smiles.count('='),  # Double bonds\n                        smiles.count('#'),  # Triple bonds\n                        smiles.count('('),  # Branching\n                    ])\n                    # Pad to 50 features\n                    while len(desc) < 50:\n                        desc.append(0.0)\n                    desc = desc[:50]  # Limit to 50\n                except Exception as e:\n                    desc = [0.0] * 50\n                \n                # Morgan fingerprint using new API\n                try:\n                    fp = self.morgan_gen.GetFingerprint(mol)\n                    fp_arr = np.array([fp.GetBit(i) for i in range(config.MORGAN_BITS)])\n                except Exception as e:\n                    fp_arr = np.zeros(config.MORGAN_BITS)\n                \n                # Combine\n                feat = np.concatenate([desc, fp_arr])\n                features.append(feat)\n                successful_extractions += 1\n            except Exception as e:\n                logger.warning(f\"Feature extraction failed for SMILES {i}: {e}\")\n                features.append(np.zeros(50 + config.MORGAN_BITS))\n        \n        features = np.array(features, dtype=np.float32)\n        if np.isnan(features).any():\n            features = np.nan_to_num(features)\n        \n        logger.info(f\"Features extracted: {features.shape}, successful: {successful_extractions}/{len(smiles_list)}\")\n        return features\n\n# Step 5: Fixed Base Model Classes\nclass BaseModel(BaseEstimator, RegressorMixin):\n    def __init__(self, params=None):\n        self.params = params or {}\n        self.model = None\n        self.is_fitted = False\n\nclass LGBMModel(BaseModel):\n    def fit(self, X, y, eval_set=None):\n        try:\n            params = {\n                'objective': 'regression',\n                'metric': 'mae',\n                'verbosity': -1,\n                'random_state': config.RANDOM_STATE,\n                'n_jobs': 1,  # Single thread for CPU efficiency\n                **self.params\n            }\n            \n            self.model = lgb.LGBMRegressor(**params)\n            \n            if eval_set is not None:\n                self.model.fit(\n                    X, y, \n                    eval_set=eval_set, \n                    callbacks=[lgb.early_stopping(config.EARLY_STOPPING_ROUNDS, verbose=False)]\n                )\n            else:\n                self.model.fit(X, y)\n            \n            self.is_fitted = True\n            logger.info(\"LGBM model fitted successfully\")\n        except Exception as e:\n            logger.error(f\"LGBM fit failed: {e}\")\n            self.is_fitted = False\n\n    def predict(self, X):\n        if self.is_fitted and self.model is not None:\n            try:\n                return self.model.predict(X)\n            except Exception as e:\n                logger.error(f\"LGBM predict failed: {e}\")\n        return np.zeros(len(X))\n\nclass XGBModel(BaseModel):\n    def fit(self, X, y, eval_set=None):\n        try:\n            params = {\n                'objective': 'reg:absoluteerror',\n                'eval_metric': 'mae',\n                'verbosity': 0,\n                'random_state': config.RANDOM_STATE,\n                'n_jobs': 1,\n                **self.params\n            }\n            \n            self.model = xgb.XGBRegressor(**params)\n            \n            if eval_set is not None:\n                self.model.fit(\n                    X, y, \n                    eval_set=eval_set, \n                    early_stopping_rounds=config.EARLY_STOPPING_ROUNDS,\n                    verbose=False\n                )\n            else:\n                self.model.fit(X, y)\n            \n            self.is_fitted = True\n            logger.info(\"XGB model fitted successfully\")\n        except Exception as e:\n            logger.error(f\"XGB fit failed: {e}\")\n            self.is_fitted = False\n\n    def predict(self, X):\n        if self.is_fitted and self.model is not None:\n            try:\n                return self.model.predict(X)\n            except Exception as e:\n                logger.error(f\"XGB predict failed: {e}\")\n        return np.zeros(len(X))\n\nclass CBModel(BaseModel):\n    def fit(self, X, y, eval_set=None):\n        try:\n            params = {\n                'loss_function': 'MAE',\n                'eval_metric': 'MAE',\n                'verbose': 0,\n                'random_state': config.RANDOM_STATE,\n                'thread_count': 1,\n                **self.params\n            }\n            \n            self.model = cb.CatBoostRegressor(**params)\n            \n            if eval_set is not None:\n                self.model.fit(\n                    X, y, \n                    eval_set=eval_set, \n                    early_stopping_rounds=config.EARLY_STOPPING_ROUNDS\n                )\n            else:\n                self.model.fit(X, y)\n            \n            self.is_fitted = True\n            logger.info(\"CatBoost model fitted successfully\")\n        except Exception as e:\n            logger.error(f\"CatBoost fit failed: {e}\")\n            self.is_fitted = False\n\n    def predict(self, X):\n        if self.is_fitted and self.model is not None:\n            try:\n                return self.model.predict(X)\n            except Exception as e:\n                logger.error(f\"CatBoost predict failed: {e}\")\n        return np.zeros(len(X))\n\n# Step 6: Fixed Hyperparameter Optimization\ndef optimize_hyperparams(model_class, X, y, folds, model_name):\n    def objective(trial):\n        if model_name == 'lgbm':\n            params = {\n                'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n                'max_depth': trial.suggest_int('max_depth', 3, 8),\n                'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0)\n            }\n        elif model_name == 'xgb':\n            params = {\n                'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n                'max_depth': trial.suggest_int('max_depth', 3, 8),\n                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0)\n            }\n        else:  # catboost\n            params = {\n                'iterations': trial.suggest_int('iterations', 100, 500),\n                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n                'depth': trial.suggest_int('depth', 3, 8),\n                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0)\n            }\n        \n        scores = []\n        for fold_idx, (train_idx, val_idx) in enumerate(folds):\n            X_train, X_val = X[train_idx], X[val_idx]\n            y_train, y_val = y[train_idx], y[val_idx]\n            \n            model = model_class(params)\n            model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n            \n            if model.is_fitted:\n                preds = model.predict(X_val)\n                score = mean_absolute_error(y_val, preds)\n                scores.append(score)\n            else:\n                scores.append(float('inf'))\n        \n        return np.mean(scores) if scores else float('inf')\n    \n    try:\n        study = optuna.create_study(direction='minimize')\n        study.optimize(objective, n_trials=config.N_TRIALS, timeout=600)  # 10 min timeout\n        logger.info(f\"{model_name} optimization completed. Best score: {study.best_value:.6f}\")\n        return study.best_params\n    except Exception as e:\n        logger.warning(f\"{model_name} optimization failed: {e}. Using default params.\")\n        return {}\n\n# Step 7: Fixed Ensemble\nclass Ensemble:\n    def __init__(self, models):\n        self.models = models\n        self.fitted_models = []\n\n    def fit(self, X, y, folds=None):\n        self.fitted_models = []\n        for model in self.models:\n            try:\n                model.fit(X, y)\n                if model.is_fitted:\n                    self.fitted_models.append(model)\n                    logger.info(f\"Added {type(model).__name__} to ensemble\")\n            except Exception as e:\n                logger.error(f\"Failed to fit {type(model).__name__}: {e}\")\n        \n        if not self.fitted_models:\n            logger.error(\"No models successfully fitted in ensemble!\")\n\n    def predict(self, X):\n        if not self.fitted_models:\n            logger.warning(\"No fitted models available, returning zeros\")\n            return np.zeros(len(X))\n        \n        predictions = []\n        for model in self.fitted_models:\n            try:\n                pred = model.predict(X)\n                if pred is not None and len(pred) == len(X):\n                    predictions.append(pred)\n            except Exception as e:\n                logger.error(f\"Prediction failed for {type(model).__name__}: {e}\")\n        \n        if predictions:\n            return np.mean(predictions, axis=0)\n        else:\n            logger.warning(\"All model predictions failed, returning zeros\")\n            return np.zeros(len(X))\n\n# Step 8: Fixed Main Pipeline\ndef main():\n    try:\n        # Load data\n        train_df, test_df = load_data()\n        \n        # Extract features\n        extractor = FeatureExtractor()\n        X_train = extractor.extract(train_df['SMILES'])\n        X_test = extractor.extract(test_df['SMILES'], is_train=False)\n        \n        # Create groups for GroupKFold (handle invalid SMILES)\n        groups = []\n        for smiles in train_df['SMILES']:\n            try:\n                mol = Chem.MolFromSmiles(smiles)\n                if mol is not None:\n                    canonical = Chem.MolToSmiles(mol)\n                    groups.append(canonical)\n                else:\n                    groups.append(smiles)\n            except:\n                groups.append(smiles)\n        \n        # GroupKFold to prevent leakage\n        gkf = GroupKFold(n_splits=config.N_FOLDS)\n        folds = list(gkf.split(X_train, groups=groups))\n        logger.info(f\"Created {len(folds)} cross-validation folds\")\n        \n        # Initialize submission\n        submission = pd.DataFrame({'id': test_df['id']})\n        \n        # Process each target\n        for target in config.TARGET_COLS:\n            logger.info(f\"Processing target: {target}\")\n            y = train_df[target].values\n            \n            # Check for missing values in target\n            if np.isnan(y).any():\n                logger.warning(f\"Found NaN values in target {target}, filling with median\")\n                y = np.nan_to_num(y, nan=np.nanmedian(y))\n            \n            # Simple default parameters (skip optimization if it fails)\n            models = []\n            \n            # Try to optimize parameters, fall back to defaults\n            try:\n                lgbm_params = optimize_hyperparams(LGBMModel, X_train, y, folds, 'lgbm')\n                if not lgbm_params:\n                    lgbm_params = {'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 6}\n                models.append(LGBMModel(lgbm_params))\n            except Exception as e:\n                logger.warning(f\"LGBM setup failed: {e}\")\n                models.append(LGBMModel({'n_estimators': 300, 'learning_rate': 0.05}))\n            \n            try:\n                xgb_params = optimize_hyperparams(XGBModel, X_train, y, folds, 'xgb')\n                if not xgb_params:\n                    xgb_params = {'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 6}\n                models.append(XGBModel(xgb_params))\n            except Exception as e:\n                logger.warning(f\"XGB setup failed: {e}\")\n                models.append(XGBModel({'n_estimators': 300, 'learning_rate': 0.05}))\n            \n            try:\n                cb_params = optimize_hyperparams(CBModel, X_train, y, folds, 'cb')\n                if not cb_params:\n                    cb_params = {'iterations': 300, 'learning_rate': 0.05, 'depth': 6}\n                models.append(CBModel(cb_params))\n            except Exception as e:\n                logger.warning(f\"CatBoost setup failed: {e}\")\n                models.append(CBModel({'iterations': 300, 'learning_rate': 0.05}))\n            \n            # Create and fit ensemble\n            ensemble = Ensemble(models)\n            ensemble.fit(X_train, y, folds)\n            \n            # Make predictions\n            preds = ensemble.predict(X_test)\n            submission[target] = preds\n            \n            logger.info(f\"Completed target: {target}\")\n            \n            # Cleanup\n            gc.collect()\n        \n        # Save submission\n        submission.to_csv('submission.csv', index=False)\n        logger.info(\"Submission generated successfully!\")\n        \n        # Display submission info\n        print(\"\\n=== SUBMISSION SUMMARY ===\")\n        print(f\"Shape: {submission.shape}\")\n        print(\"\\nFirst 5 rows:\")\n        print(submission.head())\n        print(\"\\nTarget statistics:\")\n        for col in config.TARGET_COLS:\n            if col in submission.columns:\n                print(f\"{col}: min={submission[col].min():.6f}, max={submission[col].max():.6f}, mean={submission[col].mean():.6f}\")\n        \n        return submission\n        \n    except Exception as e:\n        logger.error(f\"Main pipeline failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        \n        # Create fallback submission with zeros\n        try:\n            fallback_submission = pd.DataFrame({'id': test_df['id']})\n            for target in config.TARGET_COLS:\n                fallback_submission[target] = 0.0\n            fallback_submission.to_csv('submission.csv', index=False)\n            logger.info(\"Created fallback submission with zeros\")\n            return fallback_submission\n        except:\n            logger.error(\"Even fallback submission failed!\")\n            raise\n\n# Run the pipeline\nif __name__ == \"__main__\":\n    submission_result = main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T18:54:31.772237Z","iopub.execute_input":"2025-08-05T18:54:31.772638Z","iopub.status.idle":"2025-08-05T20:26:43.814383Z","shell.execute_reply.started":"2025-08-05T18:54:31.772608Z","shell.execute_reply":"2025-08-05T20:26:43.812909Z"}},"outputs":[{"name":"stderr","text":"[I 2025-08-05 18:54:55,625] A new study created in memory with name: no-name-901df70d-3bfb-4991-a17d-acdf655091cd\n[I 2025-08-05 18:54:59,709] Trial 0 finished with value: 6.864954010533649 and parameters: {'n_estimators': 254, 'learning_rate': 0.1463271107328461, 'max_depth': 4, 'num_leaves': 63, 'subsample': 0.8213370005881107, 'colsample_bytree': 0.9458625230317241}. Best is trial 0 with value: 6.864954010533649.\n[I 2025-08-05 18:55:03,764] Trial 1 finished with value: 6.841542973687772 and parameters: {'n_estimators': 279, 'learning_rate': 0.08961828501497593, 'max_depth': 8, 'num_leaves': 13, 'subsample': 0.9518192986446485, 'colsample_bytree': 0.9901802451585393}. Best is trial 1 with value: 6.841542973687772.\n[I 2025-08-05 18:55:07,948] Trial 2 finished with value: 6.8508235147142225 and parameters: {'n_estimators': 317, 'learning_rate': 0.036164154939923844, 'max_depth': 6, 'num_leaves': 27, 'subsample': 0.6065596653972856, 'colsample_bytree': 0.6419700308304114}. Best is trial 1 with value: 6.841542973687772.\n[I 2025-08-05 18:55:11,793] Trial 3 finished with value: 6.840271192411899 and parameters: {'n_estimators': 373, 'learning_rate': 0.19493524696886957, 'max_depth': 3, 'num_leaves': 100, 'subsample': 0.9096672718967656, 'colsample_bytree': 0.8068243543176721}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:15,952] Trial 4 finished with value: 6.91478354194463 and parameters: {'n_estimators': 328, 'learning_rate': 0.15242324617059805, 'max_depth': 8, 'num_leaves': 75, 'subsample': 0.6805934722578553, 'colsample_bytree': 0.9328411025743045}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:20,654] Trial 5 finished with value: 6.873440315004438 and parameters: {'n_estimators': 113, 'learning_rate': 0.1030671097418901, 'max_depth': 8, 'num_leaves': 62, 'subsample': 0.6757201544884934, 'colsample_bytree': 0.6075165244500171}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:24,710] Trial 6 finished with value: 6.86942086039102 and parameters: {'n_estimators': 197, 'learning_rate': 0.11568827792539986, 'max_depth': 6, 'num_leaves': 44, 'subsample': 0.6020681518153307, 'colsample_bytree': 0.9967817136771902}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:29,361] Trial 7 finished with value: 6.877444431287358 and parameters: {'n_estimators': 105, 'learning_rate': 0.11968263875814322, 'max_depth': 7, 'num_leaves': 60, 'subsample': 0.9533360875633564, 'colsample_bytree': 0.6068813370189317}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:33,742] Trial 8 finished with value: 6.856047910714006 and parameters: {'n_estimators': 199, 'learning_rate': 0.06131641480950217, 'max_depth': 7, 'num_leaves': 48, 'subsample': 0.7578486893408899, 'colsample_bytree': 0.74793857118501}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:37,886] Trial 9 finished with value: 6.85297030747747 and parameters: {'n_estimators': 198, 'learning_rate': 0.05653492937510865, 'max_depth': 7, 'num_leaves': 96, 'subsample': 0.7527609310239809, 'colsample_bytree': 0.6930337833290718}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:41,861] Trial 10 finished with value: 6.843507582199879 and parameters: {'n_estimators': 458, 'learning_rate': 0.19561870946904814, 'max_depth': 3, 'num_leaves': 96, 'subsample': 0.8661257888736608, 'colsample_bytree': 0.840874111455701}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:45,780] Trial 11 finished with value: 6.884204084357583 and parameters: {'n_estimators': 400, 'learning_rate': 0.19727015302432058, 'max_depth': 4, 'num_leaves': 21, 'subsample': 0.9844932936797717, 'colsample_bytree': 0.8513788842620031}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:49,724] Trial 12 finished with value: 6.848246120656249 and parameters: {'n_estimators': 380, 'learning_rate': 0.0854264926825093, 'max_depth': 5, 'num_leaves': 11, 'subsample': 0.9154159693708571, 'colsample_bytree': 0.7800763722265913}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:53,643] Trial 13 finished with value: 6.844361690045957 and parameters: {'n_estimators': 477, 'learning_rate': 0.1591305873856948, 'max_depth': 3, 'num_leaves': 78, 'subsample': 0.9049567463315297, 'colsample_bytree': 0.8797201039992386}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:55:57,836] Trial 14 finished with value: 6.847285642572968 and parameters: {'n_estimators': 386, 'learning_rate': 0.012636540347847655, 'max_depth': 5, 'num_leaves': 35, 'subsample': 0.8556607143509848, 'colsample_bytree': 0.7349699684070428}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:56:01,815] Trial 15 finished with value: 6.854213332174333 and parameters: {'n_estimators': 269, 'learning_rate': 0.08789746200976017, 'max_depth': 4, 'num_leaves': 81, 'subsample': 0.9958597839781679, 'colsample_bytree': 0.9967824999014041}. Best is trial 3 with value: 6.840271192411899.\n[I 2025-08-05 18:56:05,950] Trial 16 finished with value: 6.837332203706073 and parameters: {'n_estimators': 350, 'learning_rate': 0.1758306806506068, 'max_depth': 8, 'num_leaves': 11, 'subsample': 0.9210428816672678, 'colsample_bytree': 0.9145780216194068}. Best is trial 16 with value: 6.837332203706073.\n[I 2025-08-05 18:56:09,937] Trial 17 finished with value: 6.888316896782927 and parameters: {'n_estimators': 425, 'learning_rate': 0.1748848272857951, 'max_depth': 5, 'num_leaves': 36, 'subsample': 0.8753214019917563, 'colsample_bytree': 0.9025831461650263}. Best is trial 16 with value: 6.837332203706073.\n[I 2025-08-05 18:56:13,863] Trial 18 finished with value: 6.839447405959352 and parameters: {'n_estimators': 353, 'learning_rate': 0.17602087552876572, 'max_depth': 3, 'num_leaves': 100, 'subsample': 0.7803746974755777, 'colsample_bytree': 0.8099118338523551}. Best is trial 16 with value: 6.837332203706073.\n[I 2025-08-05 18:56:17,919] Trial 19 finished with value: 6.883541625362455 and parameters: {'n_estimators': 344, 'learning_rate': 0.13127065502925842, 'max_depth': 6, 'num_leaves': 84, 'subsample': 0.7824815111152048, 'colsample_bytree': 0.8136132119405697}. Best is trial 16 with value: 6.837332203706073.\n[I 2025-08-05 18:56:17,921] A new study created in memory with name: no-name-5777a421-8eac-48ef-8e77-eec971342193\n[I 2025-08-05 18:56:36,578] Trial 0 finished with value: 5.474201232705073 and parameters: {'n_estimators': 108, 'learning_rate': 0.197555962611624, 'max_depth': 3, 'subsample': 0.7339975921463779, 'colsample_bytree': 0.8546572313934304}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 18:56:55,147] Trial 1 finished with value: 5.5265119953966515 and parameters: {'n_estimators': 272, 'learning_rate': 0.13041948048406102, 'max_depth': 5, 'subsample': 0.8270808289481949, 'colsample_bytree': 0.7445776415625095}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 18:57:14,320] Trial 2 finished with value: 5.494415766360835 and parameters: {'n_estimators': 328, 'learning_rate': 0.09896794124190578, 'max_depth': 3, 'subsample': 0.7983759756087757, 'colsample_bytree': 0.8614075605407296}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 18:57:33,755] Trial 3 finished with value: 5.556364180902277 and parameters: {'n_estimators': 215, 'learning_rate': 0.19996725748208038, 'max_depth': 8, 'subsample': 0.894894665244948, 'colsample_bytree': 0.9438826604854649}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 18:57:55,760] Trial 4 finished with value: 5.492582455574586 and parameters: {'n_estimators': 409, 'learning_rate': 0.05783326325032156, 'max_depth': 3, 'subsample': 0.8674037974973237, 'colsample_bytree': 0.9447085642605964}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 18:58:14,568] Trial 5 finished with value: 5.5320412127643115 and parameters: {'n_estimators': 445, 'learning_rate': 0.060238008268881725, 'max_depth': 7, 'subsample': 0.805483365372336, 'colsample_bytree': 0.7203924371834232}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 18:58:33,292] Trial 6 finished with value: 5.527783935514755 and parameters: {'n_estimators': 413, 'learning_rate': 0.14520163388437302, 'max_depth': 6, 'subsample': 0.7422537098470836, 'colsample_bytree': 0.8965454598723459}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 18:58:51,778] Trial 7 finished with value: 5.537232979762969 and parameters: {'n_estimators': 369, 'learning_rate': 0.11371768068976028, 'max_depth': 7, 'subsample': 0.6336906170624649, 'colsample_bytree': 0.8723712884901924}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 18:59:11,058] Trial 8 finished with value: 5.477250783900372 and parameters: {'n_estimators': 304, 'learning_rate': 0.14677921005909736, 'max_depth': 3, 'subsample': 0.9471452433050438, 'colsample_bytree': 0.8651752134982424}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 18:59:30,714] Trial 9 finished with value: 5.516745464779304 and parameters: {'n_estimators': 248, 'learning_rate': 0.02705703911570475, 'max_depth': 5, 'subsample': 0.883620541473481, 'colsample_bytree': 0.7266716193735383}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 18:59:49,369] Trial 10 finished with value: 5.503634348116712 and parameters: {'n_estimators': 108, 'learning_rate': 0.19787404255861166, 'max_depth': 4, 'subsample': 0.6730012424935592, 'colsample_bytree': 0.6394308794218203}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 19:00:08,114] Trial 11 finished with value: 5.500690801023273 and parameters: {'n_estimators': 138, 'learning_rate': 0.16488823139931008, 'max_depth': 3, 'subsample': 0.9996313516946833, 'colsample_bytree': 0.8114419861436325}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 19:00:27,356] Trial 12 finished with value: 5.496800514591114 and parameters: {'n_estimators': 183, 'learning_rate': 0.16313878454479178, 'max_depth': 4, 'subsample': 0.9722817544248271, 'colsample_bytree': 0.9960476418070949}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 19:00:46,172] Trial 13 finished with value: 5.508627483012142 and parameters: {'n_estimators': 314, 'learning_rate': 0.17256993451493174, 'max_depth': 4, 'subsample': 0.7290251646803686, 'colsample_bytree': 0.7979715766659561}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 19:01:10,894] Trial 14 finished with value: 5.48579343605035 and parameters: {'n_estimators': 494, 'learning_rate': 0.09642391627208069, 'max_depth': 3, 'subsample': 0.9385420250120877, 'colsample_bytree': 0.8216350507049764}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 19:01:29,753] Trial 15 finished with value: 5.490640618152248 and parameters: {'n_estimators': 177, 'learning_rate': 0.1824156212086887, 'max_depth': 4, 'subsample': 0.7405414830805541, 'colsample_bytree': 0.6005779103861422}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 19:01:48,961] Trial 16 finished with value: 5.510917509277486 and parameters: {'n_estimators': 343, 'learning_rate': 0.14187730159134293, 'max_depth': 5, 'subsample': 0.6894957035080684, 'colsample_bytree': 0.7693518785160817}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 19:02:07,321] Trial 17 finished with value: 5.539694832101872 and parameters: {'n_estimators': 267, 'learning_rate': 0.14943832983016647, 'max_depth': 6, 'subsample': 0.6155208401601282, 'colsample_bytree': 0.9182293228290316}. Best is trial 0 with value: 5.474201232705073.\n[I 2025-08-05 19:02:30,128] Trial 18 finished with value: 5.473209386763399 and parameters: {'n_estimators': 227, 'learning_rate': 0.1180219599846871, 'max_depth': 3, 'subsample': 0.9272169006293232, 'colsample_bytree': 0.8539885772159808}. Best is trial 18 with value: 5.473209386763399.\n[I 2025-08-05 19:02:51,622] Trial 19 finished with value: 5.4986700068719525 and parameters: {'n_estimators': 101, 'learning_rate': 0.07308292702960262, 'max_depth': 4, 'subsample': 0.7738895167190832, 'colsample_bytree': 0.9960770999546033}. Best is trial 18 with value: 5.473209386763399.\n[I 2025-08-05 19:02:51,623] A new study created in memory with name: no-name-6e6a5e1c-6349-4891-bff1-c7c319affe02\n[I 2025-08-05 19:03:03,261] Trial 0 finished with value: 5.5098418379404865 and parameters: {'iterations': 290, 'learning_rate': 0.16113026186630883, 'depth': 4, 'subsample': 0.8769754630577997, 'colsample_bylevel': 0.8375372176585949}. Best is trial 0 with value: 5.5098418379404865.\n[I 2025-08-05 19:03:22,874] Trial 1 finished with value: 5.50735833146194 and parameters: {'iterations': 256, 'learning_rate': 0.08262019187637704, 'depth': 8, 'subsample': 0.8983412311370377, 'colsample_bylevel': 0.7335047965133532}. Best is trial 1 with value: 5.50735833146194.\n[I 2025-08-05 19:03:34,007] Trial 2 finished with value: 5.506771535209651 and parameters: {'iterations': 213, 'learning_rate': 0.13544673899462337, 'depth': 3, 'subsample': 0.7712544815903373, 'colsample_bylevel': 0.8600037791186204}. Best is trial 2 with value: 5.506771535209651.\n[I 2025-08-05 19:03:46,273] Trial 3 finished with value: 5.506118363103531 and parameters: {'iterations': 433, 'learning_rate': 0.19292436988795772, 'depth': 5, 'subsample': 0.9255616161035374, 'colsample_bylevel': 0.9228575883947587}. Best is trial 3 with value: 5.506118363103531.\n[I 2025-08-05 19:03:57,355] Trial 4 finished with value: 5.506422261106421 and parameters: {'iterations': 283, 'learning_rate': 0.1750886148618235, 'depth': 3, 'subsample': 0.6833866130667747, 'colsample_bylevel': 0.688646301587996}. Best is trial 3 with value: 5.506118363103531.\n[I 2025-08-05 19:04:09,538] Trial 5 finished with value: 5.491867489085645 and parameters: {'iterations': 215, 'learning_rate': 0.17119361346933007, 'depth': 5, 'subsample': 0.7088101777854007, 'colsample_bylevel': 0.652955753052644}. Best is trial 5 with value: 5.491867489085645.\n[I 2025-08-05 19:04:20,771] Trial 6 finished with value: 5.504594200933662 and parameters: {'iterations': 125, 'learning_rate': 0.12795658066008134, 'depth': 3, 'subsample': 0.9531778078671294, 'colsample_bylevel': 0.945709124419392}. Best is trial 5 with value: 5.491867489085645.\n[I 2025-08-05 19:04:32,259] Trial 7 finished with value: 5.508014178259056 and parameters: {'iterations': 480, 'learning_rate': 0.16119032438667644, 'depth': 4, 'subsample': 0.8341161668679483, 'colsample_bylevel': 0.8380161416132214}. Best is trial 5 with value: 5.491867489085645.\n[I 2025-08-05 19:04:47,569] Trial 8 finished with value: 5.4959529749498 and parameters: {'iterations': 251, 'learning_rate': 0.18365727680304983, 'depth': 7, 'subsample': 0.7547000465514027, 'colsample_bylevel': 0.88892218534484}. Best is trial 5 with value: 5.491867489085645.\n[I 2025-08-05 19:04:59,320] Trial 9 finished with value: 5.5176709276344456 and parameters: {'iterations': 193, 'learning_rate': 0.1434930103093401, 'depth': 4, 'subsample': 0.9932850801794912, 'colsample_bylevel': 0.7306516379854557}. Best is trial 5 with value: 5.491867489085645.\n[I 2025-08-05 19:05:13,267] Trial 10 finished with value: 5.5096730475631315 and parameters: {'iterations': 369, 'learning_rate': 0.03540389680651794, 'depth': 6, 'subsample': 0.6044902012022635, 'colsample_bylevel': 0.60157719376593}. Best is trial 5 with value: 5.491867489085645.\n[I 2025-08-05 19:05:28,995] Trial 11 finished with value: 5.499340829552779 and parameters: {'iterations': 122, 'learning_rate': 0.08766130739152272, 'depth': 7, 'subsample': 0.7496770866134789, 'colsample_bylevel': 0.604566284051645}. Best is trial 5 with value: 5.491867489085645.\n[I 2025-08-05 19:05:42,485] Trial 12 finished with value: 5.510695349800202 and parameters: {'iterations': 356, 'learning_rate': 0.19171596415706607, 'depth': 6, 'subsample': 0.7043084530428483, 'colsample_bylevel': 0.9034977305010823}. Best is trial 5 with value: 5.491867489085645.\n[I 2025-08-05 19:06:00,584] Trial 13 finished with value: 5.498895738552923 and parameters: {'iterations': 191, 'learning_rate': 0.19977125265129392, 'depth': 8, 'subsample': 0.660276113301203, 'colsample_bylevel': 0.7894692540320623}. Best is trial 5 with value: 5.491867489085645.\n[I 2025-08-05 19:06:16,501] Trial 14 finished with value: 5.49112724522272 and parameters: {'iterations': 357, 'learning_rate': 0.11207630038703087, 'depth': 7, 'subsample': 0.8121535329679948, 'colsample_bylevel': 0.9939551206347681}. Best is trial 14 with value: 5.49112724522272.\n[I 2025-08-05 19:06:30,202] Trial 15 finished with value: 5.490873134292327 and parameters: {'iterations': 347, 'learning_rate': 0.04701698701789975, 'depth': 5, 'subsample': 0.8156244879506354, 'colsample_bylevel': 0.998814645997657}. Best is trial 15 with value: 5.490873134292327.\n[I 2025-08-05 19:06:50,536] Trial 16 finished with value: 5.51441619043915 and parameters: {'iterations': 360, 'learning_rate': 0.017892879374465653, 'depth': 7, 'subsample': 0.8341298011563969, 'colsample_bylevel': 0.9816084707552403}. Best is trial 15 with value: 5.490873134292327.\n[I 2025-08-05 19:07:05,440] Trial 17 finished with value: 5.508056272212927 and parameters: {'iterations': 395, 'learning_rate': 0.057791376868344645, 'depth': 6, 'subsample': 0.8168706096110845, 'colsample_bylevel': 0.9962532572794792}. Best is trial 15 with value: 5.490873134292327.\n[I 2025-08-05 19:07:17,832] Trial 18 finished with value: 5.511977960696063 and parameters: {'iterations': 324, 'learning_rate': 0.10633163713009999, 'depth': 5, 'subsample': 0.8792541383656117, 'colsample_bylevel': 0.9508124515572177}. Best is trial 15 with value: 5.490873134292327.\n[I 2025-08-05 19:07:33,029] Trial 19 finished with value: 5.511343712000931 and parameters: {'iterations': 432, 'learning_rate': 0.05920579559791491, 'depth': 7, 'subsample': 0.7842586546938347, 'colsample_bylevel': 0.9662478879651302}. Best is trial 15 with value: 5.490873134292327.\n[I 2025-08-05 19:07:47,522] A new study created in memory with name: no-name-d165846e-dfe0-4ef9-9d15-a76026332a24\n[I 2025-08-05 19:07:54,104] Trial 0 finished with value: 0.010509989531946828 and parameters: {'n_estimators': 380, 'learning_rate': 0.18812985865673015, 'max_depth': 3, 'num_leaves': 22, 'subsample': 0.6209410918533625, 'colsample_bytree': 0.7688269626618324}. Best is trial 0 with value: 0.010509989531946828.\n[I 2025-08-05 19:08:00,199] Trial 1 finished with value: 0.010107185070042478 and parameters: {'n_estimators': 145, 'learning_rate': 0.12487023935617256, 'max_depth': 7, 'num_leaves': 29, 'subsample': 0.7144317050168278, 'colsample_bytree': 0.9406436751266254}. Best is trial 1 with value: 0.010107185070042478.\n[I 2025-08-05 19:08:06,159] Trial 2 finished with value: 0.009967638405713616 and parameters: {'n_estimators': 143, 'learning_rate': 0.13691278540805765, 'max_depth': 7, 'num_leaves': 52, 'subsample': 0.9378528614415969, 'colsample_bytree': 0.7752872448857194}. Best is trial 2 with value: 0.009967638405713616.\n[I 2025-08-05 19:08:12,016] Trial 3 finished with value: 0.010178155195169031 and parameters: {'n_estimators': 190, 'learning_rate': 0.1898052693014188, 'max_depth': 5, 'num_leaves': 40, 'subsample': 0.701126325319379, 'colsample_bytree': 0.7708446302376968}. Best is trial 2 with value: 0.009967638405713616.\n[I 2025-08-05 19:08:24,760] Trial 4 finished with value: 0.01049809852528648 and parameters: {'n_estimators': 313, 'learning_rate': 0.01785448286488915, 'max_depth': 8, 'num_leaves': 72, 'subsample': 0.8965067702208159, 'colsample_bytree': 0.640659820730808}. Best is trial 2 with value: 0.009967638405713616.\n[I 2025-08-05 19:08:30,081] Trial 5 finished with value: 0.01121041370101329 and parameters: {'n_estimators': 197, 'learning_rate': 0.1478965561974814, 'max_depth': 3, 'num_leaves': 31, 'subsample': 0.7192407705711366, 'colsample_bytree': 0.9135112436636225}. Best is trial 2 with value: 0.009967638405713616.\n[I 2025-08-05 19:08:36,173] Trial 6 finished with value: 0.009907315387420648 and parameters: {'n_estimators': 132, 'learning_rate': 0.12453746844127238, 'max_depth': 8, 'num_leaves': 52, 'subsample': 0.7650668783884488, 'colsample_bytree': 0.7503340796650021}. Best is trial 6 with value: 0.009907315387420648.\n[I 2025-08-05 19:08:46,276] Trial 7 finished with value: 0.00947206650827237 and parameters: {'n_estimators': 414, 'learning_rate': 0.08449715114905385, 'max_depth': 8, 'num_leaves': 58, 'subsample': 0.7464269730036377, 'colsample_bytree': 0.7309456677409641}. Best is trial 7 with value: 0.00947206650827237.\n[I 2025-08-05 19:08:52,396] Trial 8 finished with value: 0.011191564609521948 and parameters: {'n_estimators': 284, 'learning_rate': 0.1032499479363891, 'max_depth': 3, 'num_leaves': 67, 'subsample': 0.6442347562132691, 'colsample_bytree': 0.6724898274215941}. Best is trial 7 with value: 0.00947206650827237.\n[I 2025-08-05 19:08:59,640] Trial 9 finished with value: 0.00953565267798942 and parameters: {'n_estimators': 276, 'learning_rate': 0.19355238934885388, 'max_depth': 7, 'num_leaves': 41, 'subsample': 0.7069381106512899, 'colsample_bytree': 0.7090385596079305}. Best is trial 7 with value: 0.00947206650827237.\n[I 2025-08-05 19:09:09,092] Trial 10 finished with value: 0.010326478355458924 and parameters: {'n_estimators': 487, 'learning_rate': 0.052535067708159425, 'max_depth': 5, 'num_leaves': 100, 'subsample': 0.8752193280748375, 'colsample_bytree': 0.8472509581810563}. Best is trial 7 with value: 0.00947206650827237.\n[I 2025-08-05 19:09:18,861] Trial 11 finished with value: 0.009629865543559138 and parameters: {'n_estimators': 428, 'learning_rate': 0.07908706880329014, 'max_depth': 7, 'num_leaves': 76, 'subsample': 0.7998893490199397, 'colsample_bytree': 0.6880280336471305}. Best is trial 7 with value: 0.00947206650827237.\n[I 2025-08-05 19:09:30,630] Trial 12 finished with value: 0.010411965078614074 and parameters: {'n_estimators': 302, 'learning_rate': 0.06895473318571353, 'max_depth': 6, 'num_leaves': 14, 'subsample': 0.833841385563868, 'colsample_bytree': 0.6117461275009276}. Best is trial 7 with value: 0.00947206650827237.\n[I 2025-08-05 19:09:39,892] Trial 13 finished with value: 0.009294995254357463 and parameters: {'n_estimators': 380, 'learning_rate': 0.16541155805493685, 'max_depth': 8, 'num_leaves': 47, 'subsample': 0.687997262243488, 'colsample_bytree': 0.7126352250340566}. Best is trial 13 with value: 0.009294995254357463.\n[I 2025-08-05 19:09:49,821] Trial 14 finished with value: 0.009471772400037886 and parameters: {'n_estimators': 395, 'learning_rate': 0.09661944969563828, 'max_depth': 8, 'num_leaves': 61, 'subsample': 0.6578287935731912, 'colsample_bytree': 0.8574892325772475}. Best is trial 13 with value: 0.009294995254357463.\n[I 2025-08-05 19:09:58,040] Trial 15 finished with value: 0.009632091690009085 and parameters: {'n_estimators': 358, 'learning_rate': 0.15982262799390198, 'max_depth': 6, 'num_leaves': 92, 'subsample': 0.654736149713752, 'colsample_bytree': 0.8464932360225503}. Best is trial 13 with value: 0.009294995254357463.\n[I 2025-08-05 19:10:08,939] Trial 16 finished with value: 0.009193070609470352 and parameters: {'n_estimators': 481, 'learning_rate': 0.1680073570566687, 'max_depth': 8, 'num_leaves': 83, 'subsample': 0.603929586586623, 'colsample_bytree': 0.8395169770625186}. Best is trial 16 with value: 0.009193070609470352.\n[I 2025-08-05 19:10:17,234] Trial 17 finished with value: 0.01002848976904369 and parameters: {'n_estimators': 488, 'learning_rate': 0.16517973655198262, 'max_depth': 4, 'num_leaves': 85, 'subsample': 0.6003266409343407, 'colsample_bytree': 0.9796912611362242}. Best is trial 16 with value: 0.009193070609470352.\n[I 2025-08-05 19:10:26,565] Trial 18 finished with value: 0.009474845604336967 and parameters: {'n_estimators': 455, 'learning_rate': 0.16538737625550082, 'max_depth': 6, 'num_leaves': 80, 'subsample': 0.9936613639927993, 'colsample_bytree': 0.8119207120056887}. Best is trial 16 with value: 0.009193070609470352.\n[I 2025-08-05 19:10:35,711] Trial 19 finished with value: 0.009314125388560515 and parameters: {'n_estimators': 352, 'learning_rate': 0.1754299368113647, 'max_depth': 8, 'num_leaves': 42, 'subsample': 0.6591530528049278, 'colsample_bytree': 0.8968944702938818}. Best is trial 16 with value: 0.009193070609470352.\n[I 2025-08-05 19:10:35,713] A new study created in memory with name: no-name-ec278a93-2015-4b83-9f42-469c3976e729\n[I 2025-08-05 19:12:30,711] Trial 0 finished with value: 0.013537277263559551 and parameters: {'n_estimators': 284, 'learning_rate': 0.0105408512966155, 'max_depth': 4, 'subsample': 0.749312875634355, 'colsample_bytree': 0.8977793371517268}. Best is trial 0 with value: 0.013537277263559551.\n[I 2025-08-05 19:14:06,516] Trial 1 finished with value: 0.010616463231042825 and parameters: {'n_estimators': 237, 'learning_rate': 0.039494893528610124, 'max_depth': 6, 'subsample': 0.8116585483295826, 'colsample_bytree': 0.607623237170299}. Best is trial 1 with value: 0.010616463231042825.\n[I 2025-08-05 19:16:51,495] Trial 2 finished with value: 0.009048002512839557 and parameters: {'n_estimators': 470, 'learning_rate': 0.15182032448193203, 'max_depth': 6, 'subsample': 0.7734757915041859, 'colsample_bytree': 0.8271371273770574}. Best is trial 2 with value: 0.009048002512839557.\n[I 2025-08-05 19:17:45,127] Trial 3 finished with value: 0.014130081896030286 and parameters: {'n_estimators': 131, 'learning_rate': 0.025278706346210544, 'max_depth': 3, 'subsample': 0.7240977125992044, 'colsample_bytree': 0.9180376427618088}. Best is trial 2 with value: 0.009048002512839557.\n[I 2025-08-05 19:19:49,303] Trial 4 finished with value: 0.011419504686922538 and parameters: {'n_estimators': 260, 'learning_rate': 0.01405818937273548, 'max_depth': 7, 'subsample': 0.8351895766880799, 'colsample_bytree': 0.7374976036131284}. Best is trial 2 with value: 0.009048002512839557.\n[I 2025-08-05 19:21:54,170] Trial 5 finished with value: 0.009869242972475153 and parameters: {'n_estimators': 351, 'learning_rate': 0.08704777846396221, 'max_depth': 5, 'subsample': 0.7940690008282093, 'colsample_bytree': 0.7222460329422313}. Best is trial 2 with value: 0.009048002512839557.\n[I 2025-08-05 19:21:54,172] A new study created in memory with name: no-name-c0a832ba-0e81-42dd-ad9e-f3835f386718\n[I 2025-08-05 19:23:43,685] Trial 0 finished with value: 0.009267887121852598 and parameters: {'iterations': 366, 'learning_rate': 0.11387634135292979, 'depth': 8, 'subsample': 0.9865137541732967, 'colsample_bylevel': 0.9631979043562238}. Best is trial 0 with value: 0.009267887121852598.\n[I 2025-08-05 19:25:18,419] Trial 1 finished with value: 0.009254016133010228 and parameters: {'iterations': 322, 'learning_rate': 0.14433113776122872, 'depth': 8, 'subsample': 0.8383822067919852, 'colsample_bylevel': 0.9653986077095065}. Best is trial 1 with value: 0.009254016133010228.\n[I 2025-08-05 19:25:38,269] Trial 2 finished with value: 0.011540181875269801 and parameters: {'iterations': 187, 'learning_rate': 0.17204464807747086, 'depth': 3, 'subsample': 0.9180741831982707, 'colsample_bylevel': 0.8783856263368663}. Best is trial 1 with value: 0.009254016133010228.\n[I 2025-08-05 19:26:00,263] Trial 3 finished with value: 0.011961882235317968 and parameters: {'iterations': 235, 'learning_rate': 0.10414027391341608, 'depth': 3, 'subsample': 0.7682898912871634, 'colsample_bylevel': 0.633010616873535}. Best is trial 1 with value: 0.009254016133010228.\n[I 2025-08-05 19:27:31,556] Trial 4 finished with value: 0.009904828639097987 and parameters: {'iterations': 466, 'learning_rate': 0.05815763318234655, 'depth': 7, 'subsample': 0.883575399043857, 'colsample_bylevel': 0.9094425997148279}. Best is trial 1 with value: 0.009254016133010228.\n[I 2025-08-05 19:28:00,733] Trial 5 finished with value: 0.011316651193312098 and parameters: {'iterations': 158, 'learning_rate': 0.08382745916862092, 'depth': 6, 'subsample': 0.9622462484294879, 'colsample_bylevel': 0.6827638209254498}. Best is trial 1 with value: 0.009254016133010228.\n[I 2025-08-05 19:28:48,784] Trial 6 finished with value: 0.011887991005592536 and parameters: {'iterations': 227, 'learning_rate': 0.03443160720347726, 'depth': 7, 'subsample': 0.73331308294569, 'colsample_bylevel': 0.8490818230110385}. Best is trial 1 with value: 0.009254016133010228.\n[I 2025-08-05 19:29:06,649] Trial 7 finished with value: 0.015330615448103047 and parameters: {'iterations': 141, 'learning_rate': 0.01623630627997554, 'depth': 3, 'subsample': 0.8431947179574872, 'colsample_bylevel': 0.6532016226641835}. Best is trial 1 with value: 0.009254016133010228.\n[I 2025-08-05 19:29:40,587] Trial 8 finished with value: 0.011674005175180833 and parameters: {'iterations': 384, 'learning_rate': 0.05096901737713609, 'depth': 4, 'subsample': 0.6337475506550391, 'colsample_bylevel': 0.9909492479000063}. Best is trial 1 with value: 0.009254016133010228.\n[I 2025-08-05 19:30:34,437] Trial 9 finished with value: 0.009896032814212072 and parameters: {'iterations': 363, 'learning_rate': 0.1198333124033409, 'depth': 6, 'subsample': 0.8981104541448721, 'colsample_bylevel': 0.6501225430322601}. Best is trial 1 with value: 0.009254016133010228.\n[I 2025-08-05 19:32:01,007] Trial 10 finished with value: 0.009259520247562616 and parameters: {'iterations': 296, 'learning_rate': 0.19004172379386775, 'depth': 8, 'subsample': 0.6672702370793748, 'colsample_bylevel': 0.7618309088481376}. Best is trial 1 with value: 0.009254016133010228.\n[I 2025-08-05 19:32:28,639] A new study created in memory with name: no-name-c47875d4-c098-41e8-baf6-dd8d04faae9a\n[I 2025-08-05 19:32:33,143] Trial 0 finished with value: 0.007491999454137256 and parameters: {'n_estimators': 176, 'learning_rate': 0.16638358477280712, 'max_depth': 7, 'num_leaves': 70, 'subsample': 0.7621912528316559, 'colsample_bytree': 0.6729914278224235}. Best is trial 0 with value: 0.007491999454137256.\n[I 2025-08-05 19:32:38,527] Trial 1 finished with value: 0.007533472567230169 and parameters: {'n_estimators': 462, 'learning_rate': 0.11170886188058918, 'max_depth': 6, 'num_leaves': 23, 'subsample': 0.7889712637646338, 'colsample_bytree': 0.603594767782183}. Best is trial 0 with value: 0.007491999454137256.\n[I 2025-08-05 19:32:42,889] Trial 2 finished with value: 0.007800284582921755 and parameters: {'n_estimators': 435, 'learning_rate': 0.05207609217069565, 'max_depth': 3, 'num_leaves': 95, 'subsample': 0.7246124157247883, 'colsample_bytree': 0.9387052613582012}. Best is trial 0 with value: 0.007491999454137256.\n[I 2025-08-05 19:32:47,650] Trial 3 finished with value: 0.007702168503910973 and parameters: {'n_estimators': 181, 'learning_rate': 0.1967413041410437, 'max_depth': 5, 'num_leaves': 21, 'subsample': 0.7017590962050122, 'colsample_bytree': 0.6198507956891771}. Best is trial 0 with value: 0.007491999454137256.\n[I 2025-08-05 19:32:53,106] Trial 4 finished with value: 0.007432624358624185 and parameters: {'n_estimators': 379, 'learning_rate': 0.05851450826124038, 'max_depth': 8, 'num_leaves': 96, 'subsample': 0.9478900789600577, 'colsample_bytree': 0.6476937782989247}. Best is trial 4 with value: 0.007432624358624185.\n[I 2025-08-05 19:32:57,596] Trial 5 finished with value: 0.0075526276130985694 and parameters: {'n_estimators': 491, 'learning_rate': 0.152804815466021, 'max_depth': 6, 'num_leaves': 59, 'subsample': 0.9556815123369594, 'colsample_bytree': 0.8068666019882352}. Best is trial 4 with value: 0.007432624358624185.\n[I 2025-08-05 19:33:02,308] Trial 6 finished with value: 0.007704012265172997 and parameters: {'n_estimators': 356, 'learning_rate': 0.18915218758139282, 'max_depth': 5, 'num_leaves': 50, 'subsample': 0.9792021388410627, 'colsample_bytree': 0.6226705721145198}. Best is trial 4 with value: 0.007432624358624185.\n[I 2025-08-05 19:33:07,021] Trial 7 finished with value: 0.007443758284546571 and parameters: {'n_estimators': 404, 'learning_rate': 0.11345941751117397, 'max_depth': 7, 'num_leaves': 42, 'subsample': 0.6430616828302939, 'colsample_bytree': 0.9091367382471385}. Best is trial 4 with value: 0.007432624358624185.\n[I 2025-08-05 19:33:11,478] Trial 8 finished with value: 0.0078831188611136 and parameters: {'n_estimators': 497, 'learning_rate': 0.14323434585912853, 'max_depth': 3, 'num_leaves': 92, 'subsample': 0.7964059707962998, 'colsample_bytree': 0.6256199175628258}. Best is trial 4 with value: 0.007432624358624185.\n[I 2025-08-05 19:33:16,207] Trial 9 finished with value: 0.00746421701684642 and parameters: {'n_estimators': 475, 'learning_rate': 0.13793904028553408, 'max_depth': 7, 'num_leaves': 91, 'subsample': 0.7571081464599445, 'colsample_bytree': 0.7937632773162768}. Best is trial 4 with value: 0.007432624358624185.\n[I 2025-08-05 19:33:25,990] Trial 10 finished with value: 0.0073893662627754824 and parameters: {'n_estimators': 271, 'learning_rate': 0.010485549038923833, 'max_depth': 8, 'num_leaves': 76, 'subsample': 0.8902130833183732, 'colsample_bytree': 0.737747264651753}. Best is trial 10 with value: 0.0073893662627754824.\n[I 2025-08-05 19:33:35,483] Trial 11 finished with value: 0.007389900971752911 and parameters: {'n_estimators': 265, 'learning_rate': 0.010741341567259158, 'max_depth': 8, 'num_leaves': 77, 'subsample': 0.8948441029766674, 'colsample_bytree': 0.7314331114849832}. Best is trial 10 with value: 0.0073893662627754824.\n[I 2025-08-05 19:33:44,455] Trial 12 finished with value: 0.0073858515108747155 and parameters: {'n_estimators': 258, 'learning_rate': 0.011929009925303501, 'max_depth': 8, 'num_leaves': 75, 'subsample': 0.8795530752753935, 'colsample_bytree': 0.7317210684874316}. Best is trial 12 with value: 0.0073858515108747155.\n[I 2025-08-05 19:33:52,321] Trial 13 finished with value: 0.007385121962713854 and parameters: {'n_estimators': 274, 'learning_rate': 0.01478198311411469, 'max_depth': 8, 'num_leaves': 77, 'subsample': 0.8705754142073596, 'colsample_bytree': 0.7421331934196489}. Best is trial 13 with value: 0.007385121962713854.\n[I 2025-08-05 19:33:57,867] Trial 14 finished with value: 0.007410445015516546 and parameters: {'n_estimators': 221, 'learning_rate': 0.04952174384438621, 'max_depth': 8, 'num_leaves': 64, 'subsample': 0.8589900260135783, 'colsample_bytree': 0.8542818001256345}. Best is trial 13 with value: 0.007385121962713854.\n[I 2025-08-05 19:34:02,373] Trial 15 finished with value: 0.0077833194835532585 and parameters: {'n_estimators': 314, 'learning_rate': 0.0724605330464914, 'max_depth': 4, 'num_leaves': 82, 'subsample': 0.8427021831689403, 'colsample_bytree': 0.715122360429551}. Best is trial 13 with value: 0.007385121962713854.\n[I 2025-08-05 19:34:08,133] Trial 16 finished with value: 0.00743037625439564 and parameters: {'n_estimators': 100, 'learning_rate': 0.031377278585964896, 'max_depth': 7, 'num_leaves': 41, 'subsample': 0.910878683592435, 'colsample_bytree': 0.780252361608718}. Best is trial 13 with value: 0.007385121962713854.\n[I 2025-08-05 19:34:12,877] Trial 17 finished with value: 0.007521036323075549 and parameters: {'n_estimators': 319, 'learning_rate': 0.08366701377038549, 'max_depth': 6, 'num_leaves': 82, 'subsample': 0.8309073731100142, 'colsample_bytree': 0.8522702310125911}. Best is trial 13 with value: 0.007385121962713854.\n[I 2025-08-05 19:34:18,857] Trial 18 finished with value: 0.0074174917888878015 and parameters: {'n_estimators': 231, 'learning_rate': 0.03358386590550287, 'max_depth': 8, 'num_leaves': 52, 'subsample': 0.6057048750523917, 'colsample_bytree': 0.6965290095613459}. Best is trial 13 with value: 0.007385121962713854.\n[I 2025-08-05 19:34:23,696] Trial 19 finished with value: 0.007435459356903848 and parameters: {'n_estimators': 123, 'learning_rate': 0.09461967015829933, 'max_depth': 7, 'num_leaves': 67, 'subsample': 0.9287197433507796, 'colsample_bytree': 0.7620000619490169}. Best is trial 13 with value: 0.007385121962713854.\n[I 2025-08-05 19:34:23,697] A new study created in memory with name: no-name-b9e44db4-247d-4587-8d80-0bfde95a05aa\n[I 2025-08-05 19:35:02,494] Trial 0 finished with value: 0.006090943793873489 and parameters: {'n_estimators': 151, 'learning_rate': 0.05394668119876548, 'max_depth': 6, 'subsample': 0.9190277690906536, 'colsample_bytree': 0.8453988732440336}. Best is trial 0 with value: 0.006090943793873489.\n[I 2025-08-05 19:35:46,952] Trial 1 finished with value: 0.006439859163211 and parameters: {'n_estimators': 420, 'learning_rate': 0.10512587819593744, 'max_depth': 3, 'subsample': 0.6028626465798175, 'colsample_bytree': 0.7470743750316249}. Best is trial 0 with value: 0.006090943793873489.\n[I 2025-08-05 19:36:18,960] Trial 2 finished with value: 0.006097892140600145 and parameters: {'n_estimators': 345, 'learning_rate': 0.09262947918224589, 'max_depth': 6, 'subsample': 0.9350843640784957, 'colsample_bytree': 0.7860199039964764}. Best is trial 0 with value: 0.006090943793873489.\n[I 2025-08-05 19:36:46,324] Trial 3 finished with value: 0.006210976174587102 and parameters: {'n_estimators': 156, 'learning_rate': 0.12626953870038582, 'max_depth': 6, 'subsample': 0.611592308739388, 'colsample_bytree': 0.8929119102534584}. Best is trial 0 with value: 0.006090943793873489.\n[I 2025-08-05 19:37:42,454] Trial 4 finished with value: 0.006322874589772143 and parameters: {'n_estimators': 495, 'learning_rate': 0.03347358429851286, 'max_depth': 5, 'subsample': 0.8633245716488458, 'colsample_bytree': 0.7321495180627269}. Best is trial 0 with value: 0.006090943793873489.\n[I 2025-08-05 19:38:44,208] Trial 5 finished with value: 0.006639779666375876 and parameters: {'n_estimators': 257, 'learning_rate': 0.06296782291929809, 'max_depth': 3, 'subsample': 0.9706149844828993, 'colsample_bytree': 0.8017965874106887}. Best is trial 0 with value: 0.006090943793873489.\n[I 2025-08-05 19:39:08,402] Trial 6 finished with value: 0.006078597760904803 and parameters: {'n_estimators': 379, 'learning_rate': 0.11562429364772575, 'max_depth': 7, 'subsample': 0.8564447411478822, 'colsample_bytree': 0.8305847050865058}. Best is trial 6 with value: 0.006078597760904803.\n[I 2025-08-05 19:39:43,452] Trial 7 finished with value: 0.006287017474448595 and parameters: {'n_estimators': 412, 'learning_rate': 0.1473646498382259, 'max_depth': 4, 'subsample': 0.6172642746238672, 'colsample_bytree': 0.7946312152398046}. Best is trial 6 with value: 0.006078597760904803.\n[I 2025-08-05 19:40:10,511] Trial 8 finished with value: 0.006091246194439154 and parameters: {'n_estimators': 349, 'learning_rate': 0.16844195409626248, 'max_depth': 7, 'subsample': 0.8318392738386234, 'colsample_bytree': 0.6048740766682424}. Best is trial 6 with value: 0.006078597760904803.\n[I 2025-08-05 19:40:56,570] Trial 9 finished with value: 0.006403474043229468 and parameters: {'n_estimators': 271, 'learning_rate': 0.1925311381619082, 'max_depth': 3, 'subsample': 0.8595980622211352, 'colsample_bytree': 0.9013783104674072}. Best is trial 6 with value: 0.006078597760904803.\n[I 2025-08-05 19:41:28,551] Trial 10 finished with value: 0.0061131306669900175 and parameters: {'n_estimators': 488, 'learning_rate': 0.08545845182378102, 'max_depth': 8, 'subsample': 0.7183160316490195, 'colsample_bytree': 0.9886461557731768}. Best is trial 6 with value: 0.006078597760904803.\n[I 2025-08-05 19:42:12,084] Trial 11 finished with value: 0.00639152501827706 and parameters: {'n_estimators': 104, 'learning_rate': 0.013365910716474319, 'max_depth': 8, 'subsample': 0.7659784351124694, 'colsample_bytree': 0.8854131562445873}. Best is trial 6 with value: 0.006078597760904803.\n[I 2025-08-05 19:42:47,674] Trial 12 finished with value: 0.006066808670595064 and parameters: {'n_estimators': 198, 'learning_rate': 0.05415271663082573, 'max_depth': 7, 'subsample': 0.9146370871439077, 'colsample_bytree': 0.8468474129349417}. Best is trial 12 with value: 0.006066808670595064.\n[I 2025-08-05 19:43:14,115] Trial 13 finished with value: 0.0060114786328632885 and parameters: {'n_estimators': 213, 'learning_rate': 0.11645289458391951, 'max_depth': 7, 'subsample': 0.9007748324540217, 'colsample_bytree': 0.9736827669089942}. Best is trial 13 with value: 0.0060114786328632885.\n[I 2025-08-05 19:44:09,326] Trial 14 finished with value: 0.006050779273044168 and parameters: {'n_estimators': 217, 'learning_rate': 0.046261141272900715, 'max_depth': 7, 'subsample': 0.9730928363221273, 'colsample_bytree': 0.9809433302014064}. Best is trial 13 with value: 0.0060114786328632885.\n[I 2025-08-05 19:44:34,401] Trial 15 finished with value: 0.006025309369859582 and parameters: {'n_estimators': 231, 'learning_rate': 0.13235497509451138, 'max_depth': 8, 'subsample': 0.9947763615818319, 'colsample_bytree': 0.9884012150343879}. Best is trial 13 with value: 0.0060114786328632885.\n[I 2025-08-05 19:44:34,402] A new study created in memory with name: no-name-3ad292d3-3a4c-4195-b8d5-512a16860c61\n[I 2025-08-05 19:44:56,314] Trial 0 finished with value: 0.006353151130229594 and parameters: {'iterations': 189, 'learning_rate': 0.09434051513313851, 'depth': 4, 'subsample': 0.808266693044113, 'colsample_bylevel': 0.8536667302539223}. Best is trial 0 with value: 0.006353151130229594.\n[I 2025-08-05 19:45:16,383] Trial 1 finished with value: 0.006482732523451377 and parameters: {'iterations': 212, 'learning_rate': 0.17734082865739662, 'depth': 4, 'subsample': 0.8055025539232498, 'colsample_bylevel': 0.6516967993444276}. Best is trial 0 with value: 0.006353151130229594.\n[I 2025-08-05 19:46:09,844] Trial 2 finished with value: 0.0061362558188040785 and parameters: {'iterations': 372, 'learning_rate': 0.04071696820621888, 'depth': 7, 'subsample': 0.7657167551227592, 'colsample_bylevel': 0.8178357210738145}. Best is trial 2 with value: 0.0061362558188040785.\n[I 2025-08-05 19:46:39,092] Trial 3 finished with value: 0.006137302289546877 and parameters: {'iterations': 321, 'learning_rate': 0.1347768015806073, 'depth': 7, 'subsample': 0.984315142772697, 'colsample_bylevel': 0.6734787183387217}. Best is trial 2 with value: 0.0061362558188040785.\n[I 2025-08-05 19:46:57,662] Trial 4 finished with value: 0.006520160510534486 and parameters: {'iterations': 277, 'learning_rate': 0.1985296000448006, 'depth': 3, 'subsample': 0.9701299908077878, 'colsample_bylevel': 0.6111237209537298}. Best is trial 2 with value: 0.0061362558188040785.\n[I 2025-08-05 19:47:27,498] Trial 5 finished with value: 0.006174988967511204 and parameters: {'iterations': 274, 'learning_rate': 0.09751361297344388, 'depth': 5, 'subsample': 0.9213631488624646, 'colsample_bylevel': 0.9384329517545886}. Best is trial 2 with value: 0.0061362558188040785.\n[I 2025-08-05 19:47:44,565] Trial 6 finished with value: 0.00647387578280696 and parameters: {'iterations': 116, 'learning_rate': 0.10571609280801748, 'depth': 4, 'subsample': 0.855116891950689, 'colsample_bylevel': 0.9188168747907774}. Best is trial 2 with value: 0.0061362558188040785.\n[I 2025-08-05 19:48:06,729] Trial 7 finished with value: 0.006235183793331006 and parameters: {'iterations': 113, 'learning_rate': 0.19339678629195478, 'depth': 6, 'subsample': 0.7836174404752717, 'colsample_bylevel': 0.8495096619382997}. Best is trial 2 with value: 0.0061362558188040785.\n[I 2025-08-05 19:49:09,869] Trial 8 finished with value: 0.00602529114348492 and parameters: {'iterations': 469, 'learning_rate': 0.11062931350786882, 'depth': 8, 'subsample': 0.8160675156768096, 'colsample_bylevel': 0.7541661310952855}. Best is trial 8 with value: 0.00602529114348492.\n[I 2025-08-05 19:49:31,727] Trial 9 finished with value: 0.006296614557356889 and parameters: {'iterations': 195, 'learning_rate': 0.08803575070528775, 'depth': 4, 'subsample': 0.7830097863984937, 'colsample_bylevel': 0.7818389134532506}. Best is trial 8 with value: 0.00602529114348492.\n[I 2025-08-05 19:51:54,233] Trial 10 finished with value: 0.006203688757249616 and parameters: {'iterations': 500, 'learning_rate': 0.010437728957884432, 'depth': 8, 'subsample': 0.6556474419975472, 'colsample_bylevel': 0.7619674969478742}. Best is trial 8 with value: 0.00602529114348492.\n[I 2025-08-05 19:53:22,584] Trial 11 finished with value: 0.006072226107823468 and parameters: {'iterations': 448, 'learning_rate': 0.03651024402971202, 'depth': 8, 'subsample': 0.6886174010904516, 'colsample_bylevel': 0.7331484033858153}. Best is trial 8 with value: 0.00602529114348492.\n[I 2025-08-05 19:54:37,360] Trial 12 finished with value: 0.0060734142610254175 and parameters: {'iterations': 488, 'learning_rate': 0.053199639477547245, 'depth': 8, 'subsample': 0.649015120024267, 'colsample_bylevel': 0.7299714282250583}. Best is trial 8 with value: 0.00602529114348492.\n[I 2025-08-05 19:55:04,654] A new study created in memory with name: no-name-cb2b8a12-ad6b-4547-ba2a-dfe4b335cab8\n[I 2025-08-05 19:55:09,710] Trial 0 finished with value: 0.010572260658692557 and parameters: {'n_estimators': 231, 'learning_rate': 0.021113270518177053, 'max_depth': 6, 'num_leaves': 94, 'subsample': 0.6885550919470554, 'colsample_bytree': 0.6169519101961253}. Best is trial 0 with value: 0.010572260658692557.\n[I 2025-08-05 19:55:13,903] Trial 1 finished with value: 0.010602995257287782 and parameters: {'n_estimators': 430, 'learning_rate': 0.17902668348101342, 'max_depth': 5, 'num_leaves': 65, 'subsample': 0.8655971563793128, 'colsample_bytree': 0.7073057044353185}. Best is trial 0 with value: 0.010572260658692557.\n[I 2025-08-05 19:55:18,289] Trial 2 finished with value: 0.010622178066130345 and parameters: {'n_estimators': 487, 'learning_rate': 0.13665012994334338, 'max_depth': 8, 'num_leaves': 69, 'subsample': 0.6421202741731928, 'colsample_bytree': 0.771067603900895}. Best is trial 0 with value: 0.010572260658692557.\n[I 2025-08-05 19:55:22,650] Trial 3 finished with value: 0.010575570274133491 and parameters: {'n_estimators': 253, 'learning_rate': 0.10086555782946928, 'max_depth': 6, 'num_leaves': 27, 'subsample': 0.9633320732795554, 'colsample_bytree': 0.8332047660177468}. Best is trial 0 with value: 0.010572260658692557.\n[I 2025-08-05 19:55:26,812] Trial 4 finished with value: 0.010614234589525484 and parameters: {'n_estimators': 199, 'learning_rate': 0.03885938504340624, 'max_depth': 3, 'num_leaves': 55, 'subsample': 0.6143530363842908, 'colsample_bytree': 0.809181799527899}. Best is trial 0 with value: 0.010572260658692557.\n[I 2025-08-05 19:55:30,996] Trial 5 finished with value: 0.010593275631074232 and parameters: {'n_estimators': 479, 'learning_rate': 0.04714844087610417, 'max_depth': 4, 'num_leaves': 21, 'subsample': 0.9035603932052936, 'colsample_bytree': 0.9010717329538658}. Best is trial 0 with value: 0.010572260658692557.\n[I 2025-08-05 19:55:35,712] Trial 6 finished with value: 0.010596895206847503 and parameters: {'n_estimators': 307, 'learning_rate': 0.07667974596554343, 'max_depth': 7, 'num_leaves': 71, 'subsample': 0.9159884877506994, 'colsample_bytree': 0.6256327136172347}. Best is trial 0 with value: 0.010572260658692557.\n[I 2025-08-05 19:55:40,273] Trial 7 finished with value: 0.0105879521412187 and parameters: {'n_estimators': 237, 'learning_rate': 0.05016734433896957, 'max_depth': 8, 'num_leaves': 31, 'subsample': 0.8124951712302024, 'colsample_bytree': 0.6458885093840713}. Best is trial 0 with value: 0.010572260658692557.\n[I 2025-08-05 19:55:44,527] Trial 8 finished with value: 0.010576159707223722 and parameters: {'n_estimators': 465, 'learning_rate': 0.07470247066422149, 'max_depth': 5, 'num_leaves': 43, 'subsample': 0.6596714857820732, 'colsample_bytree': 0.9173625021860309}. Best is trial 0 with value: 0.010572260658692557.\n[I 2025-08-05 19:55:48,806] Trial 9 finished with value: 0.010580714208279827 and parameters: {'n_estimators': 397, 'learning_rate': 0.07580533668072649, 'max_depth': 6, 'num_leaves': 68, 'subsample': 0.9454110662101245, 'colsample_bytree': 0.7540042028263101}. Best is trial 0 with value: 0.010572260658692557.\n[I 2025-08-05 19:55:53,755] Trial 10 finished with value: 0.010567326159900896 and parameters: {'n_estimators': 116, 'learning_rate': 0.011200008546847703, 'max_depth': 7, 'num_leaves': 94, 'subsample': 0.722934796298233, 'colsample_bytree': 0.6869970872063509}. Best is trial 10 with value: 0.010567326159900896.\n[I 2025-08-05 19:55:58,431] Trial 11 finished with value: 0.010568441404097694 and parameters: {'n_estimators': 115, 'learning_rate': 0.015717321170618553, 'max_depth': 7, 'num_leaves': 100, 'subsample': 0.7314891360697, 'colsample_bytree': 0.6838494699817209}. Best is trial 10 with value: 0.010567326159900896.\n[I 2025-08-05 19:56:03,186] Trial 12 finished with value: 0.010566600916925828 and parameters: {'n_estimators': 105, 'learning_rate': 0.013083874204337386, 'max_depth': 7, 'num_leaves': 98, 'subsample': 0.7454313799612868, 'colsample_bytree': 0.6915490134155056}. Best is trial 12 with value: 0.010566600916925828.\n[I 2025-08-05 19:56:07,555] Trial 13 finished with value: 0.010632192526759553 and parameters: {'n_estimators': 110, 'learning_rate': 0.13951388033839524, 'max_depth': 7, 'num_leaves': 85, 'subsample': 0.7555039154653624, 'colsample_bytree': 0.7096359802564036}. Best is trial 12 with value: 0.010566600916925828.\n[I 2025-08-05 19:56:12,488] Trial 14 finished with value: 0.010572278001886006 and parameters: {'n_estimators': 165, 'learning_rate': 0.011961847918043793, 'max_depth': 8, 'num_leaves': 85, 'subsample': 0.8023342498418418, 'colsample_bytree': 0.7463879427441426}. Best is trial 12 with value: 0.010566600916925828.\n[I 2025-08-05 19:56:16,931] Trial 15 finished with value: 0.010584593718675343 and parameters: {'n_estimators': 337, 'learning_rate': 0.037720674554028284, 'max_depth': 7, 'num_leaves': 84, 'subsample': 0.7297115684112366, 'colsample_bytree': 0.8561037428958992}. Best is trial 12 with value: 0.010566600916925828.\n[I 2025-08-05 19:56:21,315] Trial 16 finished with value: 0.01062440501905054 and parameters: {'n_estimators': 166, 'learning_rate': 0.19501085825679532, 'max_depth': 7, 'num_leaves': 99, 'subsample': 0.7666329276636207, 'colsample_bytree': 0.9881520614736975}. Best is trial 12 with value: 0.010566600916925828.\n[I 2025-08-05 19:56:25,699] Trial 17 finished with value: 0.010593962638521883 and parameters: {'n_estimators': 150, 'learning_rate': 0.10731589547707548, 'max_depth': 6, 'num_leaves': 79, 'subsample': 0.8365892494304842, 'colsample_bytree': 0.6690681359431028}. Best is trial 12 with value: 0.010566600916925828.\n[I 2025-08-05 19:56:30,163] Trial 18 finished with value: 0.010595542371419147 and parameters: {'n_estimators': 103, 'learning_rate': 0.060515884013722376, 'max_depth': 8, 'num_leaves': 53, 'subsample': 0.6961965740166591, 'colsample_bytree': 0.7244854340593457}. Best is trial 12 with value: 0.010566600916925828.\n[I 2025-08-05 19:56:35,325] Trial 19 finished with value: 0.010576472723611095 and parameters: {'n_estimators': 280, 'learning_rate': 0.030243395466010126, 'max_depth': 5, 'num_leaves': 10, 'subsample': 0.7747837780457123, 'colsample_bytree': 0.6014445440632479}. Best is trial 12 with value: 0.010566600916925828.\n[I 2025-08-05 19:56:35,326] A new study created in memory with name: no-name-c27dfc0d-dc87-447e-93ee-ff63ef472a63\n[I 2025-08-05 19:57:05,512] Trial 0 finished with value: 0.007986155500233126 and parameters: {'n_estimators': 403, 'learning_rate': 0.031515020514967775, 'max_depth': 3, 'subsample': 0.75641801879972, 'colsample_bytree': 0.6199912533868617}. Best is trial 0 with value: 0.007986155500233126.\n[I 2025-08-05 19:57:25,985] Trial 1 finished with value: 0.0078927599132585 and parameters: {'n_estimators': 331, 'learning_rate': 0.11044876255493286, 'max_depth': 7, 'subsample': 0.9841818445586518, 'colsample_bytree': 0.8213235405311874}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 19:58:04,627] Trial 2 finished with value: 0.00796320633716235 and parameters: {'n_estimators': 303, 'learning_rate': 0.014266222349726083, 'max_depth': 5, 'subsample': 0.9535960936104367, 'colsample_bytree': 0.6437952861291226}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 19:58:26,919] Trial 3 finished with value: 0.0079734619602627 and parameters: {'n_estimators': 341, 'learning_rate': 0.031054032147618746, 'max_depth': 8, 'subsample': 0.851881210448153, 'colsample_bytree': 0.6969190334617931}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 19:58:46,066] Trial 4 finished with value: 0.007911580379714128 and parameters: {'n_estimators': 344, 'learning_rate': 0.12032729917940989, 'max_depth': 6, 'subsample': 0.6990249723593924, 'colsample_bytree': 0.6257848254579531}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 19:59:04,736] Trial 5 finished with value: 0.007930339660402571 and parameters: {'n_estimators': 270, 'learning_rate': 0.17898293492961231, 'max_depth': 8, 'subsample': 0.8435770322595996, 'colsample_bytree': 0.6225878339063806}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 19:59:31,637] Trial 6 finished with value: 0.007940832074298522 and parameters: {'n_estimators': 250, 'learning_rate': 0.06886121921985916, 'max_depth': 3, 'subsample': 0.7528452589084395, 'colsample_bytree': 0.8038333277975334}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 19:59:51,514] Trial 7 finished with value: 0.007991621462740258 and parameters: {'n_estimators': 406, 'learning_rate': 0.03258568509658768, 'max_depth': 7, 'subsample': 0.7411695122610619, 'colsample_bytree': 0.7415299394736655}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 20:00:10,737] Trial 8 finished with value: 0.007946384929273338 and parameters: {'n_estimators': 191, 'learning_rate': 0.11716354556511518, 'max_depth': 8, 'subsample': 0.736676872144046, 'colsample_bytree': 0.7828800837734885}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 20:00:30,669] Trial 9 finished with value: 0.007971771842151908 and parameters: {'n_estimators': 323, 'learning_rate': 0.15651183102500485, 'max_depth': 8, 'subsample': 0.9252461878846299, 'colsample_bytree': 0.6999013059744058}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 20:00:50,193] Trial 10 finished with value: 0.007969636314595985 and parameters: {'n_estimators': 493, 'learning_rate': 0.08349543823270804, 'max_depth': 5, 'subsample': 0.6058911053507301, 'colsample_bytree': 0.9191893114112775}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 20:01:09,378] Trial 11 finished with value: 0.007995650466476838 and parameters: {'n_estimators': 118, 'learning_rate': 0.1232194196548862, 'max_depth': 6, 'subsample': 0.6313135103124876, 'colsample_bytree': 0.8762582162630819}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 20:01:28,841] Trial 12 finished with value: 0.007970198392362777 and parameters: {'n_estimators': 389, 'learning_rate': 0.1406315986476019, 'max_depth': 6, 'subsample': 0.6749264675680021, 'colsample_bytree': 0.9826235968103172}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 20:01:51,782] Trial 13 finished with value: 0.007897359336504041 and parameters: {'n_estimators': 481, 'learning_rate': 0.07647290927160341, 'max_depth': 7, 'subsample': 0.9866286464014246, 'colsample_bytree': 0.865852948761038}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 20:02:12,271] Trial 14 finished with value: 0.00792448709468934 and parameters: {'n_estimators': 493, 'learning_rate': 0.08328899975728793, 'max_depth': 7, 'subsample': 0.9952574142106575, 'colsample_bytree': 0.8511487516301567}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 20:02:38,758] Trial 15 finished with value: 0.00792635307324502 and parameters: {'n_estimators': 442, 'learning_rate': 0.06513691843747867, 'max_depth': 7, 'subsample': 0.9074093302571522, 'colsample_bytree': 0.9148173632771025}. Best is trial 1 with value: 0.0078927599132585.\n[I 2025-08-05 20:03:08,478] Trial 16 finished with value: 0.007874364420791376 and parameters: {'n_estimators': 217, 'learning_rate': 0.10130589652360657, 'max_depth': 4, 'subsample': 0.9936575473333907, 'colsample_bytree': 0.8280641597495757}. Best is trial 16 with value: 0.007874364420791376.\n[I 2025-08-05 20:03:31,959] Trial 17 finished with value: 0.007921558133100052 and parameters: {'n_estimators': 230, 'learning_rate': 0.10175385965422165, 'max_depth': 4, 'subsample': 0.8776224679627784, 'colsample_bytree': 0.8072722704197914}. Best is trial 16 with value: 0.007874364420791376.\n[I 2025-08-05 20:03:54,453] Trial 18 finished with value: 0.007879243082139829 and parameters: {'n_estimators': 172, 'learning_rate': 0.15164385092675264, 'max_depth': 4, 'subsample': 0.8032658790775483, 'colsample_bytree': 0.7428963737669857}. Best is trial 16 with value: 0.007874364420791376.\n[I 2025-08-05 20:04:13,440] Trial 19 finished with value: 0.007885148322476639 and parameters: {'n_estimators': 140, 'learning_rate': 0.19722331907841245, 'max_depth': 4, 'subsample': 0.8039339994351629, 'colsample_bytree': 0.756038078005346}. Best is trial 16 with value: 0.007874364420791376.\n[I 2025-08-05 20:04:13,442] A new study created in memory with name: no-name-e5eec249-e38d-467a-baf1-261f67265a6c\n[I 2025-08-05 20:04:29,103] Trial 0 finished with value: 0.007985871508512052 and parameters: {'iterations': 143, 'learning_rate': 0.18404253136320398, 'depth': 6, 'subsample': 0.8051032656364127, 'colsample_bylevel': 0.945096485669907}. Best is trial 0 with value: 0.007985871508512052.\n[I 2025-08-05 20:04:48,968] Trial 1 finished with value: 0.007971703812658744 and parameters: {'iterations': 182, 'learning_rate': 0.12313961695092766, 'depth': 7, 'subsample': 0.8240981194507171, 'colsample_bylevel': 0.7540700049557825}. Best is trial 1 with value: 0.007971703812658744.\n[I 2025-08-05 20:05:10,133] Trial 2 finished with value: 0.007919953530281184 and parameters: {'iterations': 363, 'learning_rate': 0.1768230559355975, 'depth': 7, 'subsample': 0.6600661628560127, 'colsample_bylevel': 0.9107853502287565}. Best is trial 2 with value: 0.007919953530281184.\n[I 2025-08-05 20:05:42,198] Trial 3 finished with value: 0.007906780178842126 and parameters: {'iterations': 164, 'learning_rate': 0.08093827522987145, 'depth': 8, 'subsample': 0.7326909530507404, 'colsample_bylevel': 0.8454066270676547}. Best is trial 3 with value: 0.007906780178842126.\n[I 2025-08-05 20:06:00,201] Trial 4 finished with value: 0.008007439088386087 and parameters: {'iterations': 324, 'learning_rate': 0.025013576243325196, 'depth': 6, 'subsample': 0.6044470250962747, 'colsample_bylevel': 0.6887420405398164}. Best is trial 3 with value: 0.007906780178842126.\n[I 2025-08-05 20:06:26,461] Trial 5 finished with value: 0.007974370492877443 and parameters: {'iterations': 293, 'learning_rate': 0.18582958190095059, 'depth': 8, 'subsample': 0.755798824079199, 'colsample_bylevel': 0.9041095434696705}. Best is trial 3 with value: 0.007906780178842126.\n[I 2025-08-05 20:06:49,227] Trial 6 finished with value: 0.007990718176183347 and parameters: {'iterations': 179, 'learning_rate': 0.07709598103791741, 'depth': 7, 'subsample': 0.6771784286311456, 'colsample_bylevel': 0.6631886333864575}. Best is trial 3 with value: 0.007906780178842126.\n[I 2025-08-05 20:07:03,486] Trial 7 finished with value: 0.008025487547592036 and parameters: {'iterations': 375, 'learning_rate': 0.08021623915707274, 'depth': 3, 'subsample': 0.7616498259839006, 'colsample_bylevel': 0.627707700694837}. Best is trial 3 with value: 0.007906780178842126.\n[I 2025-08-05 20:07:27,004] Trial 8 finished with value: 0.007889455295810985 and parameters: {'iterations': 175, 'learning_rate': 0.15666548188267043, 'depth': 8, 'subsample': 0.9912039759610954, 'colsample_bylevel': 0.7672042812165701}. Best is trial 8 with value: 0.007889455295810985.\n[I 2025-08-05 20:07:42,381] Trial 9 finished with value: 0.007947799080142265 and parameters: {'iterations': 342, 'learning_rate': 0.17916396792708228, 'depth': 3, 'subsample': 0.732212990456338, 'colsample_bylevel': 0.8511298655010896}. Best is trial 8 with value: 0.007889455295810985.\n[I 2025-08-05 20:07:59,474] Trial 10 finished with value: 0.007980375281840873 and parameters: {'iterations': 491, 'learning_rate': 0.13584555235920623, 'depth': 5, 'subsample': 0.9997805330962104, 'colsample_bylevel': 0.751310472249531}. Best is trial 8 with value: 0.007889455295810985.\n[I 2025-08-05 20:08:39,164] Trial 11 finished with value: 0.007933248721678643 and parameters: {'iterations': 241, 'learning_rate': 0.03250352162300839, 'depth': 8, 'subsample': 0.9355406239514977, 'colsample_bylevel': 0.8250448238250367}. Best is trial 8 with value: 0.007889455295810985.\n[I 2025-08-05 20:09:05,653] Trial 12 finished with value: 0.00787708373987329 and parameters: {'iterations': 112, 'learning_rate': 0.14290359114157525, 'depth': 8, 'subsample': 0.8699047265532989, 'colsample_bylevel': 0.7742107481434861}. Best is trial 12 with value: 0.00787708373987329.\n[I 2025-08-05 20:09:20,897] Trial 13 finished with value: 0.008010007618495104 and parameters: {'iterations': 107, 'learning_rate': 0.1449581271913594, 'depth': 5, 'subsample': 0.8979678453368419, 'colsample_bylevel': 0.7528258267131986}. Best is trial 12 with value: 0.00787708373987329.\n[I 2025-08-05 20:09:46,199] Trial 14 finished with value: 0.007899073673096856 and parameters: {'iterations': 102, 'learning_rate': 0.15265685894881625, 'depth': 8, 'subsample': 0.8831700475529008, 'colsample_bylevel': 0.7097558147822493}. Best is trial 12 with value: 0.00787708373987329.\n[I 2025-08-05 20:10:10,698] Trial 15 finished with value: 0.007966122207545386 and parameters: {'iterations': 221, 'learning_rate': 0.1084688962492456, 'depth': 7, 'subsample': 0.9927150489774772, 'colsample_bylevel': 0.7961895400244667}. Best is trial 12 with value: 0.00787708373987329.\n[I 2025-08-05 20:10:24,548] Trial 16 finished with value: 0.008013655877379783 and parameters: {'iterations': 244, 'learning_rate': 0.15810841712167376, 'depth': 4, 'subsample': 0.9386482002561557, 'colsample_bylevel': 0.9953676626730835}. Best is trial 12 with value: 0.00787708373987329.\n[I 2025-08-05 20:10:40,678] Trial 17 finished with value: 0.00798190424833066 and parameters: {'iterations': 134, 'learning_rate': 0.10617351807575176, 'depth': 6, 'subsample': 0.8495290421591924, 'colsample_bylevel': 0.7952385303622731}. Best is trial 12 with value: 0.00787708373987329.\n[I 2025-08-05 20:11:12,036] Trial 18 finished with value: 0.007950276334792295 and parameters: {'iterations': 446, 'learning_rate': 0.16238150176301736, 'depth': 8, 'subsample': 0.9380448811577038, 'colsample_bylevel': 0.6010812523570457}. Best is trial 12 with value: 0.00787708373987329.\n[I 2025-08-05 20:11:28,285] Trial 19 finished with value: 0.008009260072254783 and parameters: {'iterations': 216, 'learning_rate': 0.1246607265698392, 'depth': 7, 'subsample': 0.8647653083003772, 'colsample_bylevel': 0.7166708785069377}. Best is trial 12 with value: 0.00787708373987329.\n[I 2025-08-05 20:11:40,472] A new study created in memory with name: no-name-3d96d1e3-e042-43e9-9ad5-2ad411b6fa80\n[I 2025-08-05 20:11:44,514] Trial 0 finished with value: 0.3847810633847641 and parameters: {'n_estimators': 210, 'learning_rate': 0.1297824758520117, 'max_depth': 4, 'num_leaves': 33, 'subsample': 0.7548551744083428, 'colsample_bytree': 0.873079051856128}. Best is trial 0 with value: 0.3847810633847641.\n[I 2025-08-05 20:11:48,593] Trial 1 finished with value: 0.3838669217287959 and parameters: {'n_estimators': 205, 'learning_rate': 0.1683806545060214, 'max_depth': 5, 'num_leaves': 54, 'subsample': 0.9618281557932499, 'colsample_bytree': 0.9885265374546367}. Best is trial 1 with value: 0.3838669217287959.\n[I 2025-08-05 20:11:52,564] Trial 2 finished with value: 0.38394814887830264 and parameters: {'n_estimators': 308, 'learning_rate': 0.14300312621526906, 'max_depth': 3, 'num_leaves': 23, 'subsample': 0.8911286497064197, 'colsample_bytree': 0.7035956982735836}. Best is trial 1 with value: 0.3838669217287959.\n[I 2025-08-05 20:11:56,724] Trial 3 finished with value: 0.3839997850323206 and parameters: {'n_estimators': 186, 'learning_rate': 0.030049724445414074, 'max_depth': 4, 'num_leaves': 15, 'subsample': 0.9115065284213683, 'colsample_bytree': 0.9959025523555579}. Best is trial 1 with value: 0.3838669217287959.\n[I 2025-08-05 20:12:00,680] Trial 4 finished with value: 0.3842526117200264 and parameters: {'n_estimators': 468, 'learning_rate': 0.16078899541279934, 'max_depth': 3, 'num_leaves': 52, 'subsample': 0.8774108530736808, 'colsample_bytree': 0.6953580227033993}. Best is trial 1 with value: 0.3838669217287959.\n[I 2025-08-05 20:12:05,480] Trial 5 finished with value: 0.38353989673775857 and parameters: {'n_estimators': 447, 'learning_rate': 0.04079009611866286, 'max_depth': 5, 'num_leaves': 49, 'subsample': 0.7233157988982022, 'colsample_bytree': 0.6264684700631384}. Best is trial 5 with value: 0.38353989673775857.\n[I 2025-08-05 20:12:09,824] Trial 6 finished with value: 0.3828857212286468 and parameters: {'n_estimators': 482, 'learning_rate': 0.09658634293482515, 'max_depth': 8, 'num_leaves': 25, 'subsample': 0.6864695152730224, 'colsample_bytree': 0.6728200785863115}. Best is trial 6 with value: 0.3828857212286468.\n[I 2025-08-05 20:12:14,041] Trial 7 finished with value: 0.3825734791713652 and parameters: {'n_estimators': 425, 'learning_rate': 0.1468445942241758, 'max_depth': 6, 'num_leaves': 65, 'subsample': 0.744602141379443, 'colsample_bytree': 0.8146424809759187}. Best is trial 7 with value: 0.3825734791713652.\n[I 2025-08-05 20:12:19,668] Trial 8 finished with value: 0.38299924153116977 and parameters: {'n_estimators': 275, 'learning_rate': 0.03157625090837086, 'max_depth': 8, 'num_leaves': 51, 'subsample': 0.8849937474373071, 'colsample_bytree': 0.6138942662262155}. Best is trial 7 with value: 0.3825734791713652.\n[I 2025-08-05 20:12:23,677] Trial 9 finished with value: 0.382566207565808 and parameters: {'n_estimators': 188, 'learning_rate': 0.16640381916127972, 'max_depth': 3, 'num_leaves': 87, 'subsample': 0.8785504946444629, 'colsample_bytree': 0.8198887790178971}. Best is trial 9 with value: 0.382566207565808.\n[I 2025-08-05 20:12:28,035] Trial 10 finished with value: 0.3842247444343042 and parameters: {'n_estimators': 113, 'learning_rate': 0.1997843204839462, 'max_depth': 6, 'num_leaves': 99, 'subsample': 0.6402246287033388, 'colsample_bytree': 0.8949457989424827}. Best is trial 9 with value: 0.382566207565808.\n[I 2025-08-05 20:12:32,383] Trial 11 finished with value: 0.3830877110703662 and parameters: {'n_estimators': 370, 'learning_rate': 0.0982187829041238, 'max_depth': 6, 'num_leaves': 83, 'subsample': 0.8030979666059408, 'colsample_bytree': 0.8007541885927523}. Best is trial 9 with value: 0.382566207565808.\n[I 2025-08-05 20:12:36,712] Trial 12 finished with value: 0.38396736101357654 and parameters: {'n_estimators': 360, 'learning_rate': 0.19251263459844734, 'max_depth': 7, 'num_leaves': 75, 'subsample': 0.7789803219070607, 'colsample_bytree': 0.7881880390781857}. Best is trial 9 with value: 0.382566207565808.\n[I 2025-08-05 20:12:41,159] Trial 13 finished with value: 0.38203901909844923 and parameters: {'n_estimators': 110, 'learning_rate': 0.1248129013171475, 'max_depth': 7, 'num_leaves': 74, 'subsample': 0.8191727640153672, 'colsample_bytree': 0.8015166446444846}. Best is trial 13 with value: 0.38203901909844923.\n[I 2025-08-05 20:12:45,728] Trial 14 finished with value: 0.38222847058231674 and parameters: {'n_estimators': 115, 'learning_rate': 0.06458218075549697, 'max_depth': 7, 'num_leaves': 95, 'subsample': 0.8203775146422909, 'colsample_bytree': 0.7625143058968479}. Best is trial 13 with value: 0.38203901909844923.\n[I 2025-08-05 20:12:50,294] Trial 15 finished with value: 0.38234237787304676 and parameters: {'n_estimators': 124, 'learning_rate': 0.06367019792924228, 'max_depth': 7, 'num_leaves': 95, 'subsample': 0.8183991047271095, 'colsample_bytree': 0.7570008558973803}. Best is trial 13 with value: 0.38203901909844923.\n[I 2025-08-05 20:12:54,914] Trial 16 finished with value: 0.38268215092409286 and parameters: {'n_estimators': 140, 'learning_rate': 0.06750841199146936, 'max_depth': 7, 'num_leaves': 72, 'subsample': 0.8314542901723116, 'colsample_bytree': 0.872789628321156}. Best is trial 13 with value: 0.38203901909844923.\n[I 2025-08-05 20:12:59,429] Trial 17 finished with value: 0.38358131690041297 and parameters: {'n_estimators': 250, 'learning_rate': 0.11775451233715525, 'max_depth': 8, 'num_leaves': 88, 'subsample': 0.9617438169288192, 'colsample_bytree': 0.7433925882730488}. Best is trial 13 with value: 0.38203901909844923.\n[I 2025-08-05 20:13:04,002] Trial 18 finished with value: 0.38323365507722035 and parameters: {'n_estimators': 156, 'learning_rate': 0.07603250681775835, 'max_depth': 7, 'num_leaves': 63, 'subsample': 0.6036071199274606, 'colsample_bytree': 0.9329879095276923}. Best is trial 13 with value: 0.38203901909844923.\n[I 2025-08-05 20:13:08,550] Trial 19 finished with value: 0.3830336479390977 and parameters: {'n_estimators': 107, 'learning_rate': 0.08727118811291658, 'max_depth': 7, 'num_leaves': 78, 'subsample': 0.8505788607585469, 'colsample_bytree': 0.7438168549559192}. Best is trial 13 with value: 0.38203901909844923.\n[I 2025-08-05 20:13:08,552] A new study created in memory with name: no-name-88db0ae8-844a-4d4d-91e1-f3babc647cca\n[I 2025-08-05 20:13:30,683] Trial 0 finished with value: 0.2965096319585167 and parameters: {'n_estimators': 451, 'learning_rate': 0.06950583545261292, 'max_depth': 4, 'subsample': 0.6887303101198902, 'colsample_bytree': 0.6287680190666708}. Best is trial 0 with value: 0.2965096319585167.\n[I 2025-08-05 20:13:52,341] Trial 1 finished with value: 0.2962770162572167 and parameters: {'n_estimators': 287, 'learning_rate': 0.06154137303082583, 'max_depth': 5, 'subsample': 0.9766441425506995, 'colsample_bytree': 0.9893955059537882}. Best is trial 1 with value: 0.2962770162572167.\n[I 2025-08-05 20:14:10,237] Trial 2 finished with value: 0.2956389611183708 and parameters: {'n_estimators': 137, 'learning_rate': 0.192246235873902, 'max_depth': 8, 'subsample': 0.7218062913038147, 'colsample_bytree': 0.9063818309823868}. Best is trial 2 with value: 0.2956389611183708.\n[I 2025-08-05 20:14:30,835] Trial 3 finished with value: 0.2937245678168702 and parameters: {'n_estimators': 482, 'learning_rate': 0.14374615673702734, 'max_depth': 5, 'subsample': 0.8350545122864875, 'colsample_bytree': 0.975059207699325}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:14:52,527] Trial 4 finished with value: 0.29502623656388194 and parameters: {'n_estimators': 250, 'learning_rate': 0.17273802471732946, 'max_depth': 4, 'subsample': 0.8730571662597586, 'colsample_bytree': 0.8851463610110961}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:15:10,012] Trial 5 finished with value: 0.2959718036343858 and parameters: {'n_estimators': 206, 'learning_rate': 0.1263701010552207, 'max_depth': 5, 'subsample': 0.6188677488728457, 'colsample_bytree': 0.7053743659683365}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:15:33,193] Trial 6 finished with value: 0.2953429228657526 and parameters: {'n_estimators': 342, 'learning_rate': 0.10091248339385624, 'max_depth': 4, 'subsample': 0.7927201636586589, 'colsample_bytree': 0.9725381518930167}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:15:55,028] Trial 7 finished with value: 0.29477912485521457 and parameters: {'n_estimators': 315, 'learning_rate': 0.10605049742334527, 'max_depth': 8, 'subsample': 0.8796108984362787, 'colsample_bytree': 0.7181035582590899}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:16:15,081] Trial 8 finished with value: 0.2949047135309367 and parameters: {'n_estimators': 259, 'learning_rate': 0.13738991690473396, 'max_depth': 4, 'subsample': 0.6991653706445011, 'colsample_bytree': 0.7212056769143219}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:16:36,587] Trial 9 finished with value: 0.295897951602874 and parameters: {'n_estimators': 268, 'learning_rate': 0.08833821524293303, 'max_depth': 7, 'subsample': 0.9749240019927852, 'colsample_bytree': 0.8468248699565547}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:16:56,702] Trial 10 finished with value: 0.2973910955133037 and parameters: {'n_estimators': 499, 'learning_rate': 0.013839459858458664, 'max_depth': 6, 'subsample': 0.8505980725111424, 'colsample_bytree': 0.7860543701551901}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:17:19,401] Trial 11 finished with value: 0.29389312002124546 and parameters: {'n_estimators': 380, 'learning_rate': 0.14679134655104104, 'max_depth': 8, 'subsample': 0.8868426177654101, 'colsample_bytree': 0.77039989068525}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:17:38,850] Trial 12 finished with value: 0.2942103051897361 and parameters: {'n_estimators': 393, 'learning_rate': 0.15527830096407375, 'max_depth': 6, 'subsample': 0.8006236948922609, 'colsample_bytree': 0.7916666539192853}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:18:01,015] Trial 13 finished with value: 0.29473190797127286 and parameters: {'n_estimators': 398, 'learning_rate': 0.15409364562391506, 'max_depth': 7, 'subsample': 0.9223537793553398, 'colsample_bytree': 0.8459482535630096}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:18:22,281] Trial 14 finished with value: 0.29626748828704563 and parameters: {'n_estimators': 489, 'learning_rate': 0.18774744570915652, 'max_depth': 3, 'subsample': 0.797622777627482, 'colsample_bytree': 0.937487093690573}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:18:43,096] Trial 15 finished with value: 0.2944131166300051 and parameters: {'n_estimators': 404, 'learning_rate': 0.1316381034681356, 'max_depth': 7, 'subsample': 0.9226681353469023, 'colsample_bytree': 0.6240683778506408}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:19:06,747] Trial 16 finished with value: 0.29375930247231896 and parameters: {'n_estimators': 441, 'learning_rate': 0.16418193381563692, 'max_depth': 6, 'subsample': 0.845796816505739, 'colsample_bytree': 0.7616882676091986}. Best is trial 3 with value: 0.2937245678168702.\n[I 2025-08-05 20:19:26,364] Trial 17 finished with value: 0.2928574698282659 and parameters: {'n_estimators': 458, 'learning_rate': 0.17012640571260418, 'max_depth': 6, 'subsample': 0.7562936999816318, 'colsample_bytree': 0.852818673265299}. Best is trial 17 with value: 0.2928574698282659.\n[I 2025-08-05 20:19:45,018] Trial 18 finished with value: 0.2952215001707141 and parameters: {'n_estimators': 457, 'learning_rate': 0.1965933415446216, 'max_depth': 5, 'subsample': 0.745456668332889, 'colsample_bytree': 0.9394439765355661}. Best is trial 17 with value: 0.2928574698282659.\n[I 2025-08-05 20:20:04,182] Trial 19 finished with value: 0.2955192585641301 and parameters: {'n_estimators': 352, 'learning_rate': 0.17501463193211658, 'max_depth': 3, 'subsample': 0.6319206454972562, 'colsample_bytree': 0.8436080751218511}. Best is trial 17 with value: 0.2928574698282659.\n[I 2025-08-05 20:20:04,184] A new study created in memory with name: no-name-51025f36-cce0-4580-9cbd-c893d8c49f14\n[I 2025-08-05 20:20:19,570] Trial 0 finished with value: 0.2949366509094517 and parameters: {'iterations': 217, 'learning_rate': 0.11150690640739266, 'depth': 4, 'subsample': 0.7205962123553631, 'colsample_bylevel': 0.8812759217340623}. Best is trial 0 with value: 0.2949366509094517.\n[I 2025-08-05 20:20:35,119] Trial 1 finished with value: 0.29444726231776663 and parameters: {'iterations': 196, 'learning_rate': 0.07529830682763637, 'depth': 6, 'subsample': 0.8477151075477679, 'colsample_bylevel': 0.9185581748850232}. Best is trial 1 with value: 0.29444726231776663.\n[I 2025-08-05 20:20:49,688] Trial 2 finished with value: 0.2936025260351112 and parameters: {'iterations': 303, 'learning_rate': 0.12794515300344192, 'depth': 4, 'subsample': 0.8399108108941905, 'colsample_bylevel': 0.7692183577764251}. Best is trial 2 with value: 0.2936025260351112.\n[I 2025-08-05 20:21:07,193] Trial 3 finished with value: 0.2920831938076684 and parameters: {'iterations': 118, 'learning_rate': 0.16554969862563101, 'depth': 7, 'subsample': 0.953501691187531, 'colsample_bylevel': 0.7211670112240809}. Best is trial 3 with value: 0.2920831938076684.\n[I 2025-08-05 20:21:19,586] Trial 4 finished with value: 0.2975363511714605 and parameters: {'iterations': 322, 'learning_rate': 0.045800344929360755, 'depth': 3, 'subsample': 0.8995015925360925, 'colsample_bylevel': 0.8491119013354087}. Best is trial 3 with value: 0.2920831938076684.\n[I 2025-08-05 20:21:33,146] Trial 5 finished with value: 0.2976801375753569 and parameters: {'iterations': 118, 'learning_rate': 0.024638442065784, 'depth': 3, 'subsample': 0.8532437961993145, 'colsample_bylevel': 0.650457310504902}. Best is trial 3 with value: 0.2920831938076684.\n[I 2025-08-05 20:21:48,372] Trial 6 finished with value: 0.2963414479437433 and parameters: {'iterations': 170, 'learning_rate': 0.06267030073817219, 'depth': 4, 'subsample': 0.9986174413388069, 'colsample_bylevel': 0.9460946641050103}. Best is trial 3 with value: 0.2920831938076684.\n[I 2025-08-05 20:22:04,248] Trial 7 finished with value: 0.2931356353378085 and parameters: {'iterations': 309, 'learning_rate': 0.09627720545257348, 'depth': 6, 'subsample': 0.7017540223004755, 'colsample_bylevel': 0.6190535309176736}. Best is trial 3 with value: 0.2920831938076684.\n[I 2025-08-05 20:22:26,014] Trial 8 finished with value: 0.2919240726488193 and parameters: {'iterations': 138, 'learning_rate': 0.1672257483616502, 'depth': 8, 'subsample': 0.8339057082593173, 'colsample_bylevel': 0.7253360455050872}. Best is trial 8 with value: 0.2919240726488193.\n[I 2025-08-05 20:22:52,261] Trial 9 finished with value: 0.29376263838526157 and parameters: {'iterations': 111, 'learning_rate': 0.048829171378533695, 'depth': 8, 'subsample': 0.7066010596551262, 'colsample_bylevel': 0.6231438420580524}. Best is trial 8 with value: 0.2919240726488193.\n[I 2025-08-05 20:23:17,206] Trial 10 finished with value: 0.2892772905399451 and parameters: {'iterations': 440, 'learning_rate': 0.1932707399201142, 'depth': 8, 'subsample': 0.7728700719253164, 'colsample_bylevel': 0.7228761779474702}. Best is trial 10 with value: 0.2892772905399451.\n[I 2025-08-05 20:23:36,803] Trial 11 finished with value: 0.2925281210105994 and parameters: {'iterations': 461, 'learning_rate': 0.1928580784430703, 'depth': 8, 'subsample': 0.6186557024594378, 'colsample_bylevel': 0.7206326596776876}. Best is trial 10 with value: 0.2892772905399451.\n[I 2025-08-05 20:23:55,275] Trial 12 finished with value: 0.29136149839999953 and parameters: {'iterations': 481, 'learning_rate': 0.19469028566040944, 'depth': 7, 'subsample': 0.7733111037574605, 'colsample_bylevel': 0.788463693632183}. Best is trial 10 with value: 0.2892772905399451.\n[I 2025-08-05 20:24:12,619] Trial 13 finished with value: 0.29185145468896195 and parameters: {'iterations': 491, 'learning_rate': 0.19818306319426207, 'depth': 7, 'subsample': 0.7579655060119175, 'colsample_bylevel': 0.8007235343741647}. Best is trial 10 with value: 0.2892772905399451.\n[I 2025-08-05 20:24:33,018] Trial 14 finished with value: 0.29202336304527926 and parameters: {'iterations': 409, 'learning_rate': 0.14870932821529742, 'depth': 7, 'subsample': 0.7683679523156816, 'colsample_bylevel': 0.7936714735369598}. Best is trial 10 with value: 0.2892772905399451.\n[I 2025-08-05 20:24:49,430] Trial 15 finished with value: 0.29130003021686474 and parameters: {'iterations': 391, 'learning_rate': 0.17113191353835608, 'depth': 7, 'subsample': 0.6507116379337912, 'colsample_bylevel': 0.987403505610713}. Best is trial 10 with value: 0.2892772905399451.\n[I 2025-08-05 20:25:03,753] Trial 16 finished with value: 0.29183832861200765 and parameters: {'iterations': 380, 'learning_rate': 0.16198253401333265, 'depth': 6, 'subsample': 0.6100630289695259, 'colsample_bylevel': 0.9965313677944982}. Best is trial 10 with value: 0.2892772905399451.\n[I 2025-08-05 20:25:32,747] Trial 17 finished with value: 0.2891285873337409 and parameters: {'iterations': 403, 'learning_rate': 0.13699786123047514, 'depth': 8, 'subsample': 0.6591899228256111, 'colsample_bylevel': 0.6854126967811561}. Best is trial 17 with value: 0.2891285873337409.\n[I 2025-08-05 20:25:47,888] Trial 18 finished with value: 0.2928620459195005 and parameters: {'iterations': 428, 'learning_rate': 0.1342300317860687, 'depth': 5, 'subsample': 0.6715004496017819, 'colsample_bylevel': 0.6706485779694155}. Best is trial 17 with value: 0.2891285873337409.\n[I 2025-08-05 20:26:15,640] Trial 19 finished with value: 0.29193938013325305 and parameters: {'iterations': 347, 'learning_rate': 0.10157050262015155, 'depth': 8, 'subsample': 0.6671915160548729, 'colsample_bylevel': 0.6868614977499203}. Best is trial 17 with value: 0.2891285873337409.\n","output_type":"stream"},{"name":"stdout","text":"\n=== SUBMISSION SUMMARY ===\nShape: (3, 6)\n\nFirst 5 rows:\n           id         Tg       FFV        Tc   Density         Rg\n0  1109053969  74.524287  0.376937  0.235974  0.948922  15.077610\n1  1422188626  73.108427  0.375145  0.235948  0.948925  15.069808\n2  2032016830  73.641008  0.353208  0.235973  0.948679  15.240017\n\nTarget statistics:\nTg: min=73.108427, max=74.524287, mean=73.757907\nFFV: min=0.353208, max=0.376937, mean=0.368430\nTc: min=0.235948, max=0.235974, mean=0.235965\nDensity: min=0.948679, max=0.948925, mean=0.948842\nRg: min=15.069808, max=15.240017, mean=15.129145\n","output_type":"stream"}],"execution_count":3}]}